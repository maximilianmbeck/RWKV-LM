{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/apps/userenv/beck/rwkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from wkv_kernel import WKV, WKVConfig\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the recurrence formula from CUDA to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /system/user/beck/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /system/user/beck/.cache/torch_extensions/py310_cu117/wkv/build.ninja...\n",
      "Building extension module wkv...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module wkv...\n"
     ]
    }
   ],
   "source": [
    "# Setup cuda kernel\n",
    "wkv_cuda_kernel = WKV()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input shapes from training\n",
    "batch_size = 12\n",
    "seq_len = 512\n",
    "embedding_dim = 512\n",
    "time_decay = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "time_first = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "k = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "v = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                device=device,\n",
    "                dtype=dtype).to(memory_format=torch.contiguous_format)\n",
    "y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock up for experiment\n",
    "# batch_size = 2\n",
    "# seq_len = 4\n",
    "# embedding_dim = 2\n",
    "# entries = batch_size * seq_len * embedding_dim\n",
    "# time_decay = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# time_first = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# k = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# v = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "#                 device=device).to(memory_format=torch.contiguous_format)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkv_cuda_kernel.wkv_cuda.forward(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                             time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3675,  0.3255,  1.3535,  ..., -1.0765,  0.3313, -1.2623],\n",
       "         [ 0.3631,  0.2273,  0.2391,  ..., -0.2573,  0.2292, -1.1041],\n",
       "         [ 0.4852,  0.1432, -0.6903,  ...,  0.0893,  0.2245,  0.4664],\n",
       "         ...,\n",
       "         [-0.5824,  0.1415, -1.5711,  ...,  1.4796, -0.1994,  0.0057],\n",
       "         [-0.0897,  0.0640, -0.1779,  ..., -0.7080,  0.1719,  1.2882],\n",
       "         [ 0.1788, -0.1008,  1.0149,  ..., -1.0478, -0.6345,  1.1104]],\n",
       "\n",
       "        [[ 0.4482,  1.8796,  1.0367,  ...,  0.1798,  0.1110, -0.6689],\n",
       "         [ 0.3965,  1.0164,  0.6041,  ...,  0.4157, -0.1279,  0.2094],\n",
       "         [-0.0484,  0.4225, -0.0105,  ...,  0.6572, -0.2714, -1.1611],\n",
       "         ...,\n",
       "         [-0.4828, -0.5803, -0.0811,  ..., -0.2196,  0.2380, -0.5591],\n",
       "         [ 0.5138, -0.5213,  0.5444,  ..., -0.0929,  0.5993,  0.4539],\n",
       "         [-0.4556, -0.4740,  0.4532,  ..., -0.3167, -0.3081,  0.1459]],\n",
       "\n",
       "        [[-0.3431, -1.2827, -0.1383,  ..., -0.6697,  1.0710,  1.2622],\n",
       "         [-0.3424, -1.3090, -0.0769,  ..., -0.8839,  0.8006,  0.1829],\n",
       "         [-0.2796, -0.8902, -0.0859,  ..., -0.7500,  0.8072,  0.2344],\n",
       "         ...,\n",
       "         [ 0.8852,  0.0568,  1.1095,  ...,  1.0043,  0.3191,  0.0041],\n",
       "         [ 0.6428,  0.0588,  0.6832,  ...,  0.1336,  0.6839,  0.0870],\n",
       "         [-0.5000,  0.1570,  0.4753,  ...,  0.0716,  0.5574,  0.7367]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9043,  0.0403,  1.3211,  ..., -0.0536, -0.3683,  0.4487],\n",
       "         [-0.9037,  0.0120,  0.5272,  ...,  0.7463, -0.2186,  0.2448],\n",
       "         [-0.7738,  0.2541, -0.7186,  ..., -0.3805,  0.2555, -0.1842],\n",
       "         ...,\n",
       "         [-2.5099, -0.0076,  0.7121,  ..., -0.5521, -0.4748,  0.8323],\n",
       "         [-0.2514, -0.0556,  0.6658,  ..., -0.2903, -0.4212, -0.3054],\n",
       "         [-0.2206, -0.1191,  0.6068,  ...,  0.5114, -0.1999,  1.5206]],\n",
       "\n",
       "        [[-1.1873, -1.6066,  2.0384,  ..., -0.5873, -0.6924,  0.6807],\n",
       "         [-1.1383, -0.1001,  1.9129,  ..., -0.4192,  0.1385,  0.6368],\n",
       "         [-0.9615,  0.0672,  0.9133,  ...,  0.8967, -0.0608, -0.2105],\n",
       "         ...,\n",
       "         [ 0.8659, -0.1278, -1.1534,  ..., -0.9142,  0.2349, -1.3352],\n",
       "         [ 0.7352,  0.0600,  0.2637,  ...,  0.6415, -1.3667,  0.8517],\n",
       "         [-0.0298,  0.1393, -0.4099,  ...,  1.4981, -0.8544, -0.9506]],\n",
       "\n",
       "        [[ 0.0655,  1.2896,  1.4971,  ...,  0.0098, -0.3368, -0.2662],\n",
       "         [ 0.0778,  1.3344,  1.4097,  ..., -0.5892, -0.0303,  0.8879],\n",
       "         [ 0.3586,  1.1117,  0.1767,  ..., -0.6309, -0.7305,  0.6435],\n",
       "         ...,\n",
       "         [ 0.2337,  0.2145, -0.1797,  ..., -0.0573, -1.3962,  0.4794],\n",
       "         [-0.8091,  0.2178, -0.5612,  ...,  0.0552,  0.3499,  1.1476],\n",
       "         [-0.5994,  0.2280, -0.2505,  ...,  0.2295,  0.0811, -0.2149]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduced torch version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT output:\n",
    "\n",
    "# ww = u_timefirst[c] + k[b, i, c]\n",
    "# p = max(pp, ww)\n",
    "# e1 = exp(pp - p)\n",
    "# e2 = exp(ww - p)\n",
    "# y[b, i, c] = (e1 * aa + e2 * v[b, i, c]) / (e1 * bb + e2)\n",
    "# ww = w_timedecay[c] + pp\n",
    "# p = max(ww, k[b, i, c])\n",
    "# e1 = exp(ww - p)\n",
    "# e2 = exp(k[b, i, c] - p)\n",
    "# aa = e1 * aa + e2 * v[b, i, c]\n",
    "# bb = e1 * bb + e2\n",
    "# pp = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    for b in range(batch_size):\n",
    "        for c in range(embedding_dim):\n",
    "            pp = MIN_VAL\n",
    "            aa = 0\n",
    "            bb = 0\n",
    "            for i in range(seq_len):\n",
    "                # ii = i * embedding_dim + c\n",
    "                kk = k[b, i, c]\n",
    "                vv = v[b, i, c]\n",
    "                ww = time_first[c] + kk\n",
    "                p = torch.tensor(max(pp, ww))\n",
    "                e1 = torch.exp(pp - p)\n",
    "                e2 = torch.exp(ww - p)\n",
    "                new_y = (e1 * aa + e2 * vv) / (e1 * bb + e2)\n",
    "                y[b, i, c] = new_y\n",
    "                ww = time_decay[c] + pp\n",
    "                p = torch.tensor(max(ww, kk))\n",
    "                e1 = torch.exp(ww - p)\n",
    "                e2 = torch.exp(kk - p) # uses current key\n",
    "                aa = e1 * aa + e2 * vv\n",
    "                bb = e1 * bb + e2\n",
    "                pp = p\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_m = cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "#                         time_first, k, v, y)\n",
    "# y_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v3 (own impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    for t in range(seq_len):\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m3 = cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3675,  0.3255,  1.3535,  ..., -1.0765,  0.3313, -1.2623],\n",
       "         [ 0.3631,  0.2273,  0.2391,  ..., -0.2573,  0.2292, -1.1041],\n",
       "         [ 0.4852,  0.1432, -0.6903,  ...,  0.0893,  0.2245,  0.4664],\n",
       "         ...,\n",
       "         [-0.5824,  0.1415, -1.5711,  ...,  1.4796, -0.1994,  0.0057],\n",
       "         [-0.0897,  0.0640, -0.1779,  ..., -0.7080,  0.1719,  1.2882],\n",
       "         [ 0.1788, -0.1008,  1.0149,  ..., -1.0478, -0.6345,  1.1104]],\n",
       "\n",
       "        [[ 0.4482,  1.8796,  1.0367,  ...,  0.1798,  0.1110, -0.6689],\n",
       "         [ 0.3965,  1.0164,  0.6041,  ...,  0.4157, -0.1279,  0.2094],\n",
       "         [-0.0484,  0.4225, -0.0105,  ...,  0.6572, -0.2714, -1.1611],\n",
       "         ...,\n",
       "         [-0.4828, -0.5803, -0.0811,  ..., -0.2196,  0.2380, -0.5591],\n",
       "         [ 0.5138, -0.5213,  0.5444,  ..., -0.0929,  0.5993,  0.4539],\n",
       "         [-0.4556, -0.4740,  0.4532,  ..., -0.3167, -0.3081,  0.1459]],\n",
       "\n",
       "        [[-0.3431, -1.2827, -0.1383,  ..., -0.6697,  1.0710,  1.2622],\n",
       "         [-0.3424, -1.3090, -0.0769,  ..., -0.8839,  0.8006,  0.1829],\n",
       "         [-0.2796, -0.8902, -0.0859,  ..., -0.7500,  0.8072,  0.2344],\n",
       "         ...,\n",
       "         [ 0.8852,  0.0568,  1.1095,  ...,  1.0043,  0.3191,  0.0041],\n",
       "         [ 0.6428,  0.0588,  0.6832,  ...,  0.1336,  0.6839,  0.0870],\n",
       "         [-0.5000,  0.1570,  0.4753,  ...,  0.0716,  0.5574,  0.7367]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9043,  0.0403,  1.3211,  ..., -0.0536, -0.3683,  0.4487],\n",
       "         [-0.9037,  0.0120,  0.5272,  ...,  0.7463, -0.2186,  0.2448],\n",
       "         [-0.7738,  0.2541, -0.7186,  ..., -0.3805,  0.2555, -0.1842],\n",
       "         ...,\n",
       "         [-2.5099, -0.0076,  0.7121,  ..., -0.5521, -0.4748,  0.8323],\n",
       "         [-0.2514, -0.0556,  0.6658,  ..., -0.2903, -0.4212, -0.3054],\n",
       "         [-0.2206, -0.1191,  0.6068,  ...,  0.5114, -0.1999,  1.5206]],\n",
       "\n",
       "        [[-1.1873, -1.6066,  2.0384,  ..., -0.5873, -0.6924,  0.6807],\n",
       "         [-1.1383, -0.1001,  1.9129,  ..., -0.4192,  0.1385,  0.6368],\n",
       "         [-0.9615,  0.0672,  0.9133,  ...,  0.8967, -0.0608, -0.2105],\n",
       "         ...,\n",
       "         [ 0.8659, -0.1278, -1.1534,  ..., -0.9142,  0.2349, -1.3352],\n",
       "         [ 0.7352,  0.0600,  0.2637,  ...,  0.6415, -1.3667,  0.8517],\n",
       "         [-0.0298,  0.1393, -0.4099,  ...,  1.4981, -0.8544, -0.9506]],\n",
       "\n",
       "        [[ 0.0655,  1.2896,  1.4971,  ...,  0.0098, -0.3368, -0.2662],\n",
       "         [ 0.0778,  1.3344,  1.4097,  ..., -0.5892, -0.0303,  0.8879],\n",
       "         [ 0.3586,  1.1117,  0.1767,  ..., -0.6309, -0.7305,  0.6435],\n",
       "         ...,\n",
       "         [ 0.2337,  0.2145, -0.1797,  ..., -0.0573, -1.3962,  0.4794],\n",
       "         [-0.8091,  0.2178, -0.5612,  ...,  0.0552,  0.3499,  1.1476],\n",
       "         [-0.5994,  0.2280, -0.2505,  ...,  0.2295,  0.0811, -0.2149]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m3, atol=1e-6)), print(torch.allclose(y_gt, y_m3, atol=1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3675, 0.3255],\n",
       "          [0.3631, 0.2273]],\n",
       " \n",
       "         [[0.4482, 1.8796],\n",
       "          [0.3965, 1.0164]]], device='cuda:0'),\n",
       " tensor([[[0.3675, 0.3255],\n",
       "          [0.3631, 0.2273]],\n",
       " \n",
       "         [[0.4482, 1.8796],\n",
       "          [0.3965, 1.0164]]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt[:2, :2, :2], y_m3[:2, :2, :2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single computation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "            device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 512, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape, v.shape, y.shape, time_decay.shape, time_first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = rearrange(k, 'b s e -> s b e')\n",
    "v_ = rearrange(v, 'b s e -> s b e')\n",
    "y_ = rearrange(y, 'b s e -> s b e')\n",
    "tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "td = repeat(time_decay, 'e -> b e', b=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 12, 512]),\n",
       " torch.Size([512, 12, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512]),\n",
       " torch.Size([12, 512]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_.shape, v_.shape, y.shape, td.shape, tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_VAL = -1e-38\n",
    "aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = tf + k_[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(pp, ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(pp - p)\n",
    "e2 = torch.exp(ww - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = td + pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6768, -0.0923, -1.0908,  ..., -1.0797, -0.4115, -2.0982],\n",
       "        [-1.6768, -0.0923, -1.0908,  ..., -1.0797, -0.4115, -2.0982],\n",
       "        [-1.6768, -0.0923, -1.0908,  ..., -1.0797, -0.4115, -2.0982],\n",
       "        ...,\n",
       "        [-1.6768, -0.0923, -1.0908,  ..., -1.0797, -0.4115, -2.0982],\n",
       "        [-1.6768, -0.0923, -1.0908,  ..., -1.0797, -0.4115, -2.0982],\n",
       "        [-1.6768, -0.0923, -1.0908,  ..., -1.0797, -0.4115, -2.0982]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(ww, k_[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(ww - p)\n",
    "e2 = torch.exp(k_[t] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = e1 * aa + e2 * v_[t]\n",
    "bb = e1 * bb + e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v4 (own impl, simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    # debug metrics\n",
    "    max_pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_pp = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    max_aa = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_aa = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    max_bb = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_bb = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    eps = pp\n",
    "    for t in range(seq_len):\n",
    "        # #! original version\n",
    "        # ww = tf + k_[t]\n",
    "        # p = torch.max(pp, ww)\n",
    "        # e1 = torch.exp(pp - p)\n",
    "        # e2 = torch.exp(ww - p)\n",
    "        # y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        # ww = td + pp\n",
    "        # p = torch.max(ww, k_[t])\n",
    "        # e1 = torch.exp(ww - p)\n",
    "        # e2 = torch.exp(k_[t] - p)\n",
    "        # aa = e1 * aa + e2 * v_[t]\n",
    "        # bb = e1 * bb + e2\n",
    "        # pp = p\n",
    "\n",
    "        # #? debug metrics\n",
    "        # max_pp = torch.max(max_pp, pp)\n",
    "        # min_pp = torch.min(min_pp, pp)\n",
    "        # max_aa = torch.max(max_aa, aa)\n",
    "        # min_aa = torch.min(min_aa, aa)\n",
    "        # max_bb = torch.max(max_bb, bb)\n",
    "        # min_bb = torch.min(min_bb, bb)\n",
    "        \n",
    "        #! version markus (v1) -> yields nan\n",
    "        # eps_next = torch.max(td, eps)\n",
    "        # y_[t] = (aa * torch.exp(eps-eps_next) + v_[t] * torch.exp(tf + k_[t])) / (bb * torch.exp(eps) + torch.exp(tf + k_[t]))\n",
    "\n",
    "        # aa = torch.exp(-eps_next)*(aa * torch.exp(td+eps) + v_[t] * torch.exp(k_[t]))\n",
    "        # bb = torch.exp(-eps_next)*(bb * torch.exp(td+eps) + torch.exp(k_[t]))\n",
    "        # eps = eps_next\n",
    "        \n",
    "        #! version markus (v2) -> yields nan\n",
    "        y_[t] = (aa * torch.exp(eps) + v_[t] * torch.exp(tf + k_[t])) / (bb * torch.exp(eps) + torch.exp(tf + k_[t]))\n",
    "        eps_next = torch.max(td+eps, k_[t])\n",
    "\n",
    "        aa = torch.exp(-eps_next)*(aa * torch.exp(td+eps) + v_[t] * torch.exp(k_[t]))\n",
    "        bb = torch.exp(-eps_next)*(bb * torch.exp(td+eps) + torch.exp(k_[t]))\n",
    "        eps = eps_next\n",
    "\n",
    "        #! original version (without p)\n",
    "        # ww = tf + k_[t]\n",
    "        # p = torch.max(pp, ww)\n",
    "        # e1 = torch.exp(pp)\n",
    "        # e2 = torch.exp(ww)\n",
    "        # y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        # ww = td + pp\n",
    "        # p = torch.max(ww, k_[t])\n",
    "        # e1 = torch.exp(ww)\n",
    "        # e2 = torch.exp(k_[t])\n",
    "        # aa = e1 * aa + e2 * v_[t]\n",
    "        # bb = e1 * bb + e2\n",
    "        # pp = p\n",
    "\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y, {'max_pp': max_pp, 'min_pp': min_pp, 'max_aa': max_aa, 'min_aa': min_aa, 'max_bb': max_bb, 'min_bb': min_bb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m4, ret_dict = cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3675,  0.3255,  1.3535,  ..., -1.0765,  0.3313, -1.2623],\n",
       "         [ 0.3631,  0.2273,  0.2391,  ..., -0.2573,  0.2292, -1.1041],\n",
       "         [ 0.4852,  0.1432, -0.6903,  ...,  0.0893,  0.2245,  0.4664],\n",
       "         ...,\n",
       "         [-0.5824,  0.1415, -1.5711,  ...,  1.4796, -0.1994,  0.0057],\n",
       "         [-0.0897,  0.0640, -0.1779,  ..., -0.7080,  0.1719,  1.2882],\n",
       "         [ 0.1788, -0.1008,  1.0149,  ..., -1.0478, -0.6345,  1.1104]],\n",
       "\n",
       "        [[ 0.4482,  1.8796,  1.0367,  ...,  0.1798,  0.1110, -0.6689],\n",
       "         [ 0.3965,  1.0164,  0.6041,  ...,  0.4157, -0.1279,  0.2094],\n",
       "         [-0.0484,  0.4225, -0.0105,  ...,  0.6572, -0.2714, -1.1611],\n",
       "         ...,\n",
       "         [-0.4828, -0.5803, -0.0811,  ..., -0.2196,  0.2380, -0.5591],\n",
       "         [ 0.5138, -0.5213,  0.5444,  ..., -0.0929,  0.5993,  0.4539],\n",
       "         [-0.4556, -0.4740,  0.4532,  ..., -0.3167, -0.3081,  0.1459]],\n",
       "\n",
       "        [[-0.3431, -1.2827, -0.1383,  ..., -0.6697,  1.0710,  1.2622],\n",
       "         [-0.3424, -1.3090, -0.0769,  ..., -0.8839,  0.8006,  0.1829],\n",
       "         [-0.2796, -0.8902, -0.0859,  ..., -0.7500,  0.8072,  0.2344],\n",
       "         ...,\n",
       "         [ 0.8852,  0.0568,  1.1095,  ...,  1.0043,  0.3191,  0.0041],\n",
       "         [ 0.6428,  0.0588,  0.6832,  ...,  0.1336,  0.6839,  0.0870],\n",
       "         [-0.5000,  0.1570,  0.4753,  ...,  0.0716,  0.5574,  0.7367]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9043,  0.0403,  1.3211,  ..., -0.0536, -0.3683,  0.4487],\n",
       "         [-0.9037,  0.0120,  0.5272,  ...,  0.7463, -0.2186,  0.2448],\n",
       "         [-0.7738,  0.2541, -0.7186,  ..., -0.3805,  0.2555, -0.1842],\n",
       "         ...,\n",
       "         [-2.5099, -0.0076,  0.7121,  ..., -0.5521, -0.4748,  0.8323],\n",
       "         [-0.2514, -0.0556,  0.6658,  ..., -0.2903, -0.4212, -0.3054],\n",
       "         [-0.2206, -0.1191,  0.6068,  ...,  0.5114, -0.1999,  1.5206]],\n",
       "\n",
       "        [[-1.1873, -1.6066,  2.0384,  ..., -0.5873, -0.6924,  0.6807],\n",
       "         [-1.1383, -0.1001,  1.9129,  ..., -0.4192,  0.1385,  0.6368],\n",
       "         [-0.9615,  0.0672,  0.9133,  ...,  0.8967, -0.0608, -0.2105],\n",
       "         ...,\n",
       "         [ 0.8659, -0.1278, -1.1534,  ..., -0.9142,  0.2349, -1.3352],\n",
       "         [ 0.7352,  0.0600,  0.2637,  ...,  0.6415, -1.3667,  0.8517],\n",
       "         [-0.0298,  0.1393, -0.4099,  ...,  1.4981, -0.8544, -0.9506]],\n",
       "\n",
       "        [[ 0.0655,  1.2896,  1.4971,  ...,  0.0098, -0.3368, -0.2662],\n",
       "         [ 0.0778,  1.3344,  1.4097,  ..., -0.5892, -0.0303,  0.8879],\n",
       "         [ 0.3586,  1.1117,  0.1767,  ..., -0.6309, -0.7305,  0.6435],\n",
       "         ...,\n",
       "         [ 0.2337,  0.2145, -0.1797,  ..., -0.0573, -1.3962,  0.4794],\n",
       "         [-0.8091,  0.2178, -0.5612,  ...,  0.0552,  0.3499,  1.1476],\n",
       "         [-0.5994,  0.2280, -0.2505,  ...,  0.2295,  0.0811, -0.2149]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False tensor(True, device='cuda:0') tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m4, atol=1e-6), y_m4.isnan().any(), y_gt.isnan().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! markus version\n",
    "# B = 1\n",
    "# T = 512\n",
    "# C = 1\n",
    "\n",
    "# _w = torch.randn((C))\n",
    "# _u = torch.randn((C))\n",
    "# _k = torch.randn((B, T, C))\n",
    "# _v = torch.randn((B, T, C))\n",
    "\n",
    "# min_value = torch.tensor(-1e38).float()\n",
    "\n",
    "# w = -torch.exp(_w.float())\n",
    "# u = _u.float()\n",
    "# k = _k.float()\n",
    "# v = _v.float()\n",
    "# y = torch.empty(B, T, C)\n",
    "\n",
    "\n",
    "# for c in range(C):\n",
    "#     eps = min_value\n",
    "#     aa = 0\n",
    "#     bb = 0\n",
    "#     for t in range(T):\n",
    "#         kk = k[0,t,c]\n",
    "#         vv = v[0,t,c]\n",
    "\n",
    "#         y[0,t,c] = (torch.exp(eps) * aa + torch.exp(u[c] + kk) * vv) / (torch.exp(eps) * bb + torch.exp(u[c] + kk))\n",
    "\n",
    "#         eps_next = torch.max(w[c] + eps, kk)\n",
    "\n",
    "#         aa = torch.exp(-eps_next) * (torch.exp(w[c] + eps) * aa + torch.exp(kk) * vv)\n",
    "#         bb = torch.exp(-eps_next) * (torch.exp(w[c] + eps) * bb + torch.exp(kk))\n",
    "#         eps = eps_next\n",
    "\n",
    "# display(any(y.view(-1).isnan().tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at max and min values of running sums\n",
    "In each step we use elementwise max/min operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[962.1312, 420.1057, 299.8172,  ...,   3.4283, 567.4110,   3.1173],\n",
       "        [963.3484, 420.1945, 299.9291,  ...,   2.6842, 567.6777,   3.2462],\n",
       "        [963.5245, 421.1901, 299.7128,  ...,   3.0347, 567.0105,   3.5679],\n",
       "        ...,\n",
       "        [961.6948, 419.0993, 299.4191,  ...,   2.8203, 566.3354,   3.6480],\n",
       "        [963.6456, 420.1425, 299.1628,  ...,   3.1260, 565.8119,   2.1868],\n",
       "        [964.7355, 420.5218, 300.3070,  ...,   2.9727, 566.9648,   2.5999]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['max_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3030, -1.8639,  0.5374,  ..., -2.2211,  0.4580, -0.7061],\n",
       "        [ 0.1641, -0.2136, -2.0325,  ..., -2.5894,  0.7247, -0.9738],\n",
       "        [ 0.3401,  0.7821,  0.8226,  ..., -2.2132,  0.0575, -0.4266],\n",
       "        ...,\n",
       "        [-1.6317, -1.3087, -0.3186,  ..., -2.2139, -0.6175, -0.6660],\n",
       "        [-0.6776, -0.2841,  0.2726,  ..., -2.2243, -1.1411, -0.3897],\n",
       "        [ 1.5512,  0.1138,  1.4169,  ..., -3.0105,  0.0118, -0.6453]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['min_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3175,  0.7887, -0.0513,  ...,  3.2844, -2.4227,  4.3941],\n",
       "         [-1.1903, -0.6233,  1.1964,  ...,  3.4967, -0.0087,  4.6466],\n",
       "         [ 0.7404,  0.5722,  2.1244,  ...,  3.3701,  0.3867,  3.8458],\n",
       "         ...,\n",
       "         [ 0.3901,  0.3522, -0.3350,  ...,  3.5138,  1.4386,  3.9051],\n",
       "         [-0.1157,  1.1631,  2.0237,  ...,  2.9620,  0.5157,  4.9913],\n",
       "         [-0.0926,  2.0300,  1.2441,  ...,  3.3179, -0.5801,  2.9114]],\n",
       "        device='cuda:0'),\n",
       " tensor(13.5066, device='cuda:0'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['max_aa'], torch.max(ret_dict['max_aa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1641,  0.1188, -0.8389,  ..., -4.0240, -2.4821, -3.7610],\n",
       "         [-1.2051, -1.0781,  0.7027,  ..., -2.9647, -0.2947, -4.1991],\n",
       "         [ 0.6287,  0.3607,  1.0143,  ..., -2.7821, -0.2213, -4.3683],\n",
       "         ...,\n",
       "         [-0.0684, -0.6464, -0.8603,  ..., -4.2799,  1.0761, -3.8674],\n",
       "         [-1.6427, -0.0430,  1.7798,  ..., -3.2646, -0.2280, -3.8984],\n",
       "         [-0.1059,  1.6882,  0.3863,  ..., -3.2564, -0.7386, -5.3694]],\n",
       "        device='cuda:0'),\n",
       " tensor(-7.8673, device='cuda:0'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['min_aa'], torch.min(ret_dict['min_aa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.8313, 1.9966, 2.3150,  ..., 2.8648, 1.1176, 8.9634],\n",
       "         [1.0387, 1.8036, 1.6067,  ..., 2.7565, 1.3202, 9.2702],\n",
       "         [1.2204, 1.3959, 2.5086,  ..., 2.6329, 1.4677, 8.5003],\n",
       "         ...,\n",
       "         [2.0314, 2.1810, 1.7666,  ..., 2.9097, 1.6132, 8.1550],\n",
       "         [1.3392, 2.9483, 2.1127,  ..., 2.5649, 2.2604, 8.0671],\n",
       "         [1.0262, 2.2889, 1.9205,  ..., 2.6718, 1.2837, 9.3124]],\n",
       "        device='cuda:0'),\n",
       " tensor(59.7912, device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['max_bb'], torch.max(ret_dict['max_bb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0'),\n",
       " tensor(1., device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['min_bb'], torch.min(ret_dict['min_bb'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### understand wkv try 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "# seq_len = 4\n",
    "# embedding_dim = 2\n",
    "# entries = batch_size * seq_len * embedding_dim\n",
    "# time_decay = 0.1 * (1+torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format))\n",
    "# time_first = 2* (1+torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format))\n",
    "# k = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# v = 5-torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "#                 device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1000, 0.2000], device='cuda:0'),\n",
       " tensor([2., 4.], device='cuda:0'),\n",
       " tensor([[[0., 1.],\n",
       "          [2., 3.],\n",
       "          [4., 5.],\n",
       "          [6., 7.]]], device='cuda:0'),\n",
       " tensor([[[ 5.,  4.],\n",
       "          [ 3.,  2.],\n",
       "          [ 1.,  0.],\n",
       "          [-1., -2.]]], device='cuda:0'))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_decay, time_first, k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_understand(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    # debug metrics\n",
    "    max_pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_pp = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    max_aa = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_aa = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    max_bb = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_bb = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    eps = pp\n",
    "    for t in range(seq_len):\n",
    "        #! original version\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "        print(f'{t}: pp {pp}, aa {aa}, bb {bb}, y {y_[t]}')\n",
    "        #? debug metrics\n",
    "        max_pp = torch.max(max_pp, pp)\n",
    "        min_pp = torch.min(min_pp, pp)\n",
    "        max_aa = torch.max(max_aa, aa)\n",
    "        min_aa = torch.min(min_aa, aa)\n",
    "        max_bb = torch.max(max_bb, bb)\n",
    "        min_bb = torch.min(min_bb, bb)\n",
    "\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y, {'max_pp': max_pp, 'min_pp': min_pp, 'max_aa': max_aa, 'min_aa': min_aa, 'max_bb': max_bb, 'min_bb': min_bb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: pp tensor([[0., 1.]], device='cuda:0'), aa tensor([[5., 4.]], device='cuda:0'), bb tensor([[1., 1.]], device='cuda:0'), y tensor([[5., 4.]], device='cuda:0')\n",
      "1: pp tensor([[2., 3.]], device='cuda:0'), aa tensor([[3.7478, 2.6612]], device='cuda:0'), bb tensor([[1.1496, 1.1653]], device='cuda:0'), y tensor([[3.0360, 2.0049]], device='cuda:0')\n",
      "2: pp tensor([[4., 5.]], device='cuda:0'), aa tensor([[1.5606, 0.4399]], device='cuda:0'), bb tensor([[1.1719, 1.1926]], device='cuda:0'), y tensor([[1.0466, 0.0066]], device='cuda:0')\n",
      "3: pp tensor([[6., 7.]], device='cuda:0'), aa tensor([[-0.7666, -1.9273]], device='cuda:0'), bb tensor([[1.1753, 1.1971]], device='cuda:0'), y tensor([[-0.9510, -1.9930]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y, ret_dict = cuda_forward_understand(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.0000,  4.0000],\n",
       "         [ 3.0360,  2.0049],\n",
       "         [ 1.0466,  0.0066],\n",
       "         [-0.9510, -1.9930]]], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.allclose(y_gt, y_m4, atol=1e-5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
