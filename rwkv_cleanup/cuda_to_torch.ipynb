{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/apps/userenv/beck/rwkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from wkv_kernel import WKV, WKVConfig\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the recurrence formula from CUDA to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /system/user/beck/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /system/user/beck/.cache/torch_extensions/py310_cu117/wkv/build.ninja...\n",
      "Building extension module wkv...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module wkv...\n"
     ]
    }
   ],
   "source": [
    "# Setup cuda kernel\n",
    "wkv_cuda_kernel = WKV()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input shapes from training\n",
    "batch_size = 12\n",
    "seq_len = 512\n",
    "embedding_dim = 512\n",
    "time_decay = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "time_first = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "k = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "v = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                device=device,\n",
    "                dtype=dtype).to(memory_format=torch.contiguous_format)\n",
    "y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock up for experiment\n",
    "# batch_size = 2\n",
    "# seq_len = 4\n",
    "# embedding_dim = 2\n",
    "# entries = batch_size * seq_len * embedding_dim\n",
    "# time_decay = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# time_first = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# k = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# v = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "#                 device=device).to(memory_format=torch.contiguous_format)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkv_cuda_kernel.wkv_cuda.forward(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                             time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0037e+00, -8.6573e-02,  8.0910e-01,  ...,  7.8404e-01,\n",
       "           8.3063e-01, -4.3740e-02],\n",
       "         [ 1.1826e+00,  5.2133e-01,  8.1488e-01,  ...,  3.4065e-01,\n",
       "           7.3034e-01, -2.9765e-01],\n",
       "         [-2.8041e-01,  2.7679e-01,  6.9914e-01,  ...,  1.9742e-01,\n",
       "           1.0599e+00, -6.8128e-01],\n",
       "         ...,\n",
       "         [-3.0968e-01,  2.4749e-01,  4.4073e-01,  ..., -4.4695e-01,\n",
       "           8.7492e-02, -5.6729e-03],\n",
       "         [ 6.1573e-01,  2.4749e-01,  5.6366e-01,  ..., -3.8346e-01,\n",
       "           8.7492e-02,  7.1407e-04],\n",
       "         [ 8.1210e-01,  2.4749e-01,  6.9856e-01,  ..., -4.3334e-01,\n",
       "           8.7492e-02, -6.5013e-02]],\n",
       "\n",
       "        [[-1.2718e+00,  1.0147e+00, -2.2606e-01,  ..., -6.5893e-01,\n",
       "          -2.4915e-01, -4.5347e-01],\n",
       "         [-8.1836e-01,  9.2059e-01,  7.4954e-01,  ..., -3.6657e-01,\n",
       "          -1.0068e-01, -5.9264e-01],\n",
       "         [ 3.4145e-01,  6.0618e-01,  9.1639e-01,  ...,  3.7305e-01,\n",
       "           1.0906e-01,  4.2963e-01],\n",
       "         ...,\n",
       "         [ 1.8321e-01,  4.6658e-01,  3.8975e-01,  ...,  3.9486e-03,\n",
       "          -4.5449e-02, -1.2768e+00],\n",
       "         [-5.1952e-02,  4.6658e-01,  2.2170e-02,  ...,  8.2788e-02,\n",
       "          -4.5449e-02, -5.1009e-01],\n",
       "         [-2.3008e-01,  4.6658e-01, -1.1107e-01,  ...,  3.0911e-01,\n",
       "          -4.5449e-02, -4.2350e-01]],\n",
       "\n",
       "        [[ 1.2551e+00, -1.8248e+00,  3.2201e-01,  ..., -9.8289e-01,\n",
       "          -8.1189e-01, -8.1094e-01],\n",
       "         [ 9.9184e-01, -7.8628e-01, -1.0857e-01,  ..., -8.9145e-01,\n",
       "          -9.2682e-01, -5.3171e-01],\n",
       "         [ 3.8171e-01, -9.6550e-01, -1.7308e-01,  ..., -5.6741e-01,\n",
       "           3.5699e-01, -1.6026e-01],\n",
       "         ...,\n",
       "         [ 6.8127e-02, -3.8056e-01,  1.8154e-01,  ..., -5.3637e-02,\n",
       "          -3.3603e-02, -2.9100e-01],\n",
       "         [-3.8578e-01, -3.8056e-01, -5.6068e-02,  ...,  3.4062e-01,\n",
       "          -3.3603e-02, -1.1097e-02],\n",
       "         [-1.1270e+00, -3.8056e-01,  2.2226e-01,  ...,  9.7817e-01,\n",
       "          -3.3603e-02,  1.9712e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7743e+00,  6.3751e-01,  1.1520e+00,  ...,  1.3523e+00,\n",
       "           3.2321e-01,  1.2044e+00],\n",
       "         [-6.8871e-01, -2.1601e-02,  9.1087e-01,  ..., -5.3533e-01,\n",
       "          -7.7034e-01,  9.3268e-01],\n",
       "         [-3.9805e-01, -3.0973e-01,  5.8892e-01,  ..., -7.5891e-01,\n",
       "          -1.6524e+00,  4.3841e-01],\n",
       "         ...,\n",
       "         [-1.0513e+00, -7.4496e-02, -4.1171e-01,  ..., -7.5852e-01,\n",
       "          -7.0371e-01,  7.3972e-02],\n",
       "         [-1.1963e-01, -7.4496e-02, -3.5475e-01,  ..., -9.0874e-01,\n",
       "          -7.0371e-01,  2.1557e-01],\n",
       "         [-1.5080e-01, -7.4496e-02, -3.8481e-01,  ..., -5.4616e-01,\n",
       "          -7.0371e-01,  4.9015e-02]],\n",
       "\n",
       "        [[-6.4876e-01,  1.5580e+00, -1.4496e+00,  ...,  4.4083e-01,\n",
       "           1.8468e-01,  1.6197e+00],\n",
       "         [-1.7171e-01,  1.2330e+00, -1.4645e+00,  ...,  5.0449e-01,\n",
       "           1.3833e+00, -1.7778e-01],\n",
       "         [ 3.7030e-01,  1.2177e+00, -1.4297e+00,  ...,  6.7499e-01,\n",
       "          -1.3375e-01,  5.2582e-02],\n",
       "         ...,\n",
       "         [ 2.9672e-01,  9.3933e-01, -1.8115e-01,  ..., -4.1821e-01,\n",
       "          -1.3504e-01, -3.1655e-01],\n",
       "         [ 2.9225e-01,  9.3933e-01, -4.0603e-01,  ..., -2.8719e-01,\n",
       "          -1.3504e-01, -8.5010e-01],\n",
       "         [-8.1852e-01,  9.3933e-01, -6.4785e-01,  ..., -7.5491e-01,\n",
       "          -1.3504e-01, -6.8007e-01]],\n",
       "\n",
       "        [[-6.8197e-01,  3.5533e-01,  2.9951e-01,  ...,  1.8684e-01,\n",
       "           1.1379e+00, -1.8221e-01],\n",
       "         [-1.0659e+00,  2.8676e-01,  3.9293e-01,  ...,  2.0612e-01,\n",
       "           8.7881e-01,  1.3179e-01],\n",
       "         [-9.3567e-01,  1.9362e-01,  5.4992e-01,  ...,  9.4352e-01,\n",
       "           5.5305e-01,  1.8029e-02],\n",
       "         ...,\n",
       "         [ 5.6541e-02,  5.2198e-01,  4.2959e-01,  ..., -1.5588e-01,\n",
       "           1.2126e-01,  4.8665e-01],\n",
       "         [ 9.0296e-02,  5.2198e-01,  1.0414e-01,  ...,  4.0699e-02,\n",
       "           1.2126e-01,  1.1235e-01],\n",
       "         [-1.7889e-01,  5.2198e-01,  1.9348e-01,  ..., -4.7904e-02,\n",
       "           1.2126e-01,  1.2904e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduced torch version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT output:\n",
    "\n",
    "# ww = u_timefirst[c] + k[b, i, c]\n",
    "# p = max(pp, ww)\n",
    "# e1 = exp(pp - p)\n",
    "# e2 = exp(ww - p)\n",
    "# y[b, i, c] = (e1 * aa + e2 * v[b, i, c]) / (e1 * bb + e2)\n",
    "# ww = w_timedecay[c] + pp\n",
    "# p = max(ww, k[b, i, c])\n",
    "# e1 = exp(ww - p)\n",
    "# e2 = exp(k[b, i, c] - p)\n",
    "# aa = e1 * aa + e2 * v[b, i, c]\n",
    "# bb = e1 * bb + e2\n",
    "# pp = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    for b in range(batch_size):\n",
    "        for c in range(embedding_dim):\n",
    "            pp = MIN_VAL\n",
    "            aa = 0\n",
    "            bb = 0\n",
    "            for i in range(seq_len):\n",
    "                # ii = i * embedding_dim + c\n",
    "                kk = k[b, i, c]\n",
    "                vv = v[b, i, c]\n",
    "                ww = time_first[c] + kk\n",
    "                p = torch.tensor(max(pp, ww))\n",
    "                e1 = torch.exp(pp - p)\n",
    "                e2 = torch.exp(ww - p)\n",
    "                new_y = (e1 * aa + e2 * vv) / (e1 * bb + e2)\n",
    "                y[b, i, c] = new_y\n",
    "                ww = time_decay[c] + pp\n",
    "                p = torch.tensor(max(ww, kk))\n",
    "                e1 = torch.exp(ww - p)\n",
    "                e2 = torch.exp(kk - p) # uses current key\n",
    "                aa = e1 * aa + e2 * vv\n",
    "                bb = e1 * bb + e2\n",
    "                pp = p\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_m = cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "#                         time_first, k, v, y)\n",
    "# y_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v3 (own impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    for t in range(seq_len):\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m3 = cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0037e+00, -8.6573e-02,  8.0910e-01,  ...,  7.8404e-01,\n",
       "           8.3063e-01, -4.3740e-02],\n",
       "         [ 1.1826e+00,  5.2133e-01,  8.1488e-01,  ...,  3.4065e-01,\n",
       "           7.3034e-01, -2.9765e-01],\n",
       "         [-2.8041e-01,  2.7679e-01,  6.9914e-01,  ...,  1.9742e-01,\n",
       "           1.0599e+00, -6.8128e-01],\n",
       "         ...,\n",
       "         [-3.0968e-01,  2.4749e-01,  4.4073e-01,  ..., -4.4695e-01,\n",
       "           8.7492e-02, -5.6729e-03],\n",
       "         [ 6.1573e-01,  2.4749e-01,  5.6366e-01,  ..., -3.8346e-01,\n",
       "           8.7492e-02,  7.1407e-04],\n",
       "         [ 8.1210e-01,  2.4749e-01,  6.9856e-01,  ..., -4.3334e-01,\n",
       "           8.7492e-02, -6.5013e-02]],\n",
       "\n",
       "        [[-1.2718e+00,  1.0147e+00, -2.2606e-01,  ..., -6.5893e-01,\n",
       "          -2.4915e-01, -4.5347e-01],\n",
       "         [-8.1836e-01,  9.2059e-01,  7.4954e-01,  ..., -3.6657e-01,\n",
       "          -1.0068e-01, -5.9264e-01],\n",
       "         [ 3.4145e-01,  6.0618e-01,  9.1639e-01,  ...,  3.7305e-01,\n",
       "           1.0906e-01,  4.2963e-01],\n",
       "         ...,\n",
       "         [ 1.8321e-01,  4.6658e-01,  3.8975e-01,  ...,  3.9486e-03,\n",
       "          -4.5449e-02, -1.2768e+00],\n",
       "         [-5.1952e-02,  4.6658e-01,  2.2170e-02,  ...,  8.2788e-02,\n",
       "          -4.5449e-02, -5.1009e-01],\n",
       "         [-2.3008e-01,  4.6658e-01, -1.1107e-01,  ...,  3.0911e-01,\n",
       "          -4.5449e-02, -4.2350e-01]],\n",
       "\n",
       "        [[ 1.2551e+00, -1.8248e+00,  3.2201e-01,  ..., -9.8289e-01,\n",
       "          -8.1189e-01, -8.1094e-01],\n",
       "         [ 9.9184e-01, -7.8628e-01, -1.0857e-01,  ..., -8.9145e-01,\n",
       "          -9.2682e-01, -5.3171e-01],\n",
       "         [ 3.8171e-01, -9.6550e-01, -1.7308e-01,  ..., -5.6741e-01,\n",
       "           3.5699e-01, -1.6026e-01],\n",
       "         ...,\n",
       "         [ 6.8127e-02, -3.8056e-01,  1.8154e-01,  ..., -5.3637e-02,\n",
       "          -3.3603e-02, -2.9100e-01],\n",
       "         [-3.8578e-01, -3.8056e-01, -5.6068e-02,  ...,  3.4062e-01,\n",
       "          -3.3603e-02, -1.1097e-02],\n",
       "         [-1.1270e+00, -3.8056e-01,  2.2226e-01,  ...,  9.7817e-01,\n",
       "          -3.3603e-02,  1.9712e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7743e+00,  6.3751e-01,  1.1520e+00,  ...,  1.3523e+00,\n",
       "           3.2321e-01,  1.2044e+00],\n",
       "         [-6.8871e-01, -2.1601e-02,  9.1087e-01,  ..., -5.3533e-01,\n",
       "          -7.7034e-01,  9.3268e-01],\n",
       "         [-3.9805e-01, -3.0973e-01,  5.8892e-01,  ..., -7.5891e-01,\n",
       "          -1.6524e+00,  4.3841e-01],\n",
       "         ...,\n",
       "         [-1.0513e+00, -7.4496e-02, -4.1171e-01,  ..., -7.5852e-01,\n",
       "          -7.0371e-01,  7.3972e-02],\n",
       "         [-1.1963e-01, -7.4496e-02, -3.5475e-01,  ..., -9.0874e-01,\n",
       "          -7.0371e-01,  2.1557e-01],\n",
       "         [-1.5080e-01, -7.4496e-02, -3.8481e-01,  ..., -5.4616e-01,\n",
       "          -7.0371e-01,  4.9015e-02]],\n",
       "\n",
       "        [[-6.4876e-01,  1.5580e+00, -1.4496e+00,  ...,  4.4083e-01,\n",
       "           1.8468e-01,  1.6197e+00],\n",
       "         [-1.7171e-01,  1.2330e+00, -1.4645e+00,  ...,  5.0449e-01,\n",
       "           1.3833e+00, -1.7778e-01],\n",
       "         [ 3.7030e-01,  1.2177e+00, -1.4297e+00,  ...,  6.7499e-01,\n",
       "          -1.3375e-01,  5.2582e-02],\n",
       "         ...,\n",
       "         [ 2.9672e-01,  9.3933e-01, -1.8115e-01,  ..., -4.1821e-01,\n",
       "          -1.3504e-01, -3.1655e-01],\n",
       "         [ 2.9225e-01,  9.3933e-01, -4.0603e-01,  ..., -2.8719e-01,\n",
       "          -1.3504e-01, -8.5010e-01],\n",
       "         [-8.1852e-01,  9.3933e-01, -6.4785e-01,  ..., -7.5491e-01,\n",
       "          -1.3504e-01, -6.8007e-01]],\n",
       "\n",
       "        [[-6.8197e-01,  3.5533e-01,  2.9951e-01,  ...,  1.8684e-01,\n",
       "           1.1379e+00, -1.8221e-01],\n",
       "         [-1.0659e+00,  2.8676e-01,  3.9293e-01,  ...,  2.0612e-01,\n",
       "           8.7881e-01,  1.3179e-01],\n",
       "         [-9.3567e-01,  1.9362e-01,  5.4992e-01,  ...,  9.4352e-01,\n",
       "           5.5305e-01,  1.8029e-02],\n",
       "         ...,\n",
       "         [ 5.6541e-02,  5.2198e-01,  4.2959e-01,  ..., -1.5588e-01,\n",
       "           1.2126e-01,  4.8665e-01],\n",
       "         [ 9.0296e-02,  5.2198e-01,  1.0414e-01,  ...,  4.0699e-02,\n",
       "           1.2126e-01,  1.1235e-01],\n",
       "         [-1.7889e-01,  5.2198e-01,  1.9348e-01,  ..., -4.7904e-02,\n",
       "           1.2126e-01,  1.2904e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m3, atol=1e-6)), print(torch.allclose(y_gt, y_m3, atol=1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0037, -0.0866],\n",
       "          [ 1.1826,  0.5213]],\n",
       " \n",
       "         [[-1.2718,  1.0147],\n",
       "          [-0.8184,  0.9206]]], device='cuda:0'),\n",
       " tensor([[[-1.0037, -0.0866],\n",
       "          [ 1.1826,  0.5213]],\n",
       " \n",
       "         [[-1.2718,  1.0147],\n",
       "          [-0.8184,  0.9206]]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt[:2, :2, :2], y_m3[:2, :2, :2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single computation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "            device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 512, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape, v.shape, y.shape, time_decay.shape, time_first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = rearrange(k, 'b s e -> s b e')\n",
    "v_ = rearrange(v, 'b s e -> s b e')\n",
    "y_ = rearrange(y, 'b s e -> s b e')\n",
    "tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "td = repeat(time_decay, 'e -> b e', b=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 12, 512]),\n",
       " torch.Size([512, 12, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512]),\n",
       " torch.Size([12, 512]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_.shape, v_.shape, y.shape, td.shape, tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_VAL = -1e-38\n",
    "aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = tf + k_[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(pp, ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(pp - p)\n",
    "e2 = torch.exp(ww - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = td + pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5128,  0.2325, -0.4114,  ..., -0.6003,  0.1299, -0.2464],\n",
       "        [-0.5128,  0.2325, -0.4114,  ..., -0.6003,  0.1299, -0.2464],\n",
       "        [-0.5128,  0.2325, -0.4114,  ..., -0.6003,  0.1299, -0.2464],\n",
       "        ...,\n",
       "        [-0.5128,  0.2325, -0.4114,  ..., -0.6003,  0.1299, -0.2464],\n",
       "        [-0.5128,  0.2325, -0.4114,  ..., -0.6003,  0.1299, -0.2464],\n",
       "        [-0.5128,  0.2325, -0.4114,  ..., -0.6003,  0.1299, -0.2464]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(ww, k_[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(ww - p)\n",
    "e2 = torch.exp(k_[t] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = e1 * aa + e2 * v_[t]\n",
    "bb = e1 * bb + e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v4 (own impl, simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    for t in range(seq_len):\n",
    "        # ww = tf + k_[t]\n",
    "        # p = torch.max(pp, ww)\n",
    "        # e1 = torch.exp(pp - p)\n",
    "        # e2 = torch.exp(ww - p)\n",
    "        # y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        # ww = td + pp\n",
    "        # p = torch.max(ww, k_[t])\n",
    "        # e1 = torch.exp(ww - p)\n",
    "        # e2 = torch.exp(k_[t] - p)\n",
    "        # aa = e1 * aa + e2 * v_[t]\n",
    "        # bb = e1 * bb + e2\n",
    "        # pp = p\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m4 = cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0037e+00, -8.6573e-02,  8.0910e-01,  ...,  7.8404e-01,\n",
       "           8.3063e-01, -4.3740e-02],\n",
       "         [ 1.1826e+00,  5.2133e-01,  8.1488e-01,  ...,  3.4065e-01,\n",
       "           7.3034e-01, -2.9765e-01],\n",
       "         [-2.8041e-01,  2.7679e-01,  6.9914e-01,  ...,  1.9742e-01,\n",
       "           1.0599e+00, -6.8128e-01],\n",
       "         ...,\n",
       "         [-3.0968e-01,  2.4749e-01,  4.4073e-01,  ..., -4.4695e-01,\n",
       "           8.7492e-02, -5.6729e-03],\n",
       "         [ 6.1573e-01,  2.4749e-01,  5.6366e-01,  ..., -3.8346e-01,\n",
       "           8.7492e-02,  7.1407e-04],\n",
       "         [ 8.1210e-01,  2.4749e-01,  6.9856e-01,  ..., -4.3334e-01,\n",
       "           8.7492e-02, -6.5013e-02]],\n",
       "\n",
       "        [[-1.2718e+00,  1.0147e+00, -2.2606e-01,  ..., -6.5893e-01,\n",
       "          -2.4915e-01, -4.5347e-01],\n",
       "         [-8.1836e-01,  9.2059e-01,  7.4954e-01,  ..., -3.6657e-01,\n",
       "          -1.0068e-01, -5.9264e-01],\n",
       "         [ 3.4145e-01,  6.0618e-01,  9.1639e-01,  ...,  3.7305e-01,\n",
       "           1.0906e-01,  4.2963e-01],\n",
       "         ...,\n",
       "         [ 1.8321e-01,  4.6658e-01,  3.8975e-01,  ...,  3.9486e-03,\n",
       "          -4.5449e-02, -1.2768e+00],\n",
       "         [-5.1952e-02,  4.6658e-01,  2.2170e-02,  ...,  8.2788e-02,\n",
       "          -4.5449e-02, -5.1009e-01],\n",
       "         [-2.3008e-01,  4.6658e-01, -1.1107e-01,  ...,  3.0911e-01,\n",
       "          -4.5449e-02, -4.2350e-01]],\n",
       "\n",
       "        [[ 1.2551e+00, -1.8248e+00,  3.2201e-01,  ..., -9.8289e-01,\n",
       "          -8.1189e-01, -8.1094e-01],\n",
       "         [ 9.9184e-01, -7.8628e-01, -1.0857e-01,  ..., -8.9145e-01,\n",
       "          -9.2682e-01, -5.3171e-01],\n",
       "         [ 3.8171e-01, -9.6550e-01, -1.7308e-01,  ..., -5.6741e-01,\n",
       "           3.5699e-01, -1.6026e-01],\n",
       "         ...,\n",
       "         [ 6.8127e-02, -3.8056e-01,  1.8154e-01,  ..., -5.3637e-02,\n",
       "          -3.3603e-02, -2.9100e-01],\n",
       "         [-3.8578e-01, -3.8056e-01, -5.6068e-02,  ...,  3.4062e-01,\n",
       "          -3.3603e-02, -1.1097e-02],\n",
       "         [-1.1270e+00, -3.8056e-01,  2.2226e-01,  ...,  9.7817e-01,\n",
       "          -3.3603e-02,  1.9712e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7743e+00,  6.3751e-01,  1.1520e+00,  ...,  1.3523e+00,\n",
       "           3.2321e-01,  1.2044e+00],\n",
       "         [-6.8871e-01, -2.1601e-02,  9.1087e-01,  ..., -5.3533e-01,\n",
       "          -7.7034e-01,  9.3268e-01],\n",
       "         [-3.9805e-01, -3.0973e-01,  5.8892e-01,  ..., -7.5891e-01,\n",
       "          -1.6524e+00,  4.3841e-01],\n",
       "         ...,\n",
       "         [-1.0513e+00, -7.4496e-02, -4.1171e-01,  ..., -7.5852e-01,\n",
       "          -7.0371e-01,  7.3972e-02],\n",
       "         [-1.1963e-01, -7.4496e-02, -3.5475e-01,  ..., -9.0874e-01,\n",
       "          -7.0371e-01,  2.1557e-01],\n",
       "         [-1.5080e-01, -7.4496e-02, -3.8481e-01,  ..., -5.4616e-01,\n",
       "          -7.0371e-01,  4.9015e-02]],\n",
       "\n",
       "        [[-6.4876e-01,  1.5580e+00, -1.4496e+00,  ...,  4.4083e-01,\n",
       "           1.8468e-01,  1.6197e+00],\n",
       "         [-1.7171e-01,  1.2330e+00, -1.4645e+00,  ...,  5.0449e-01,\n",
       "           1.3833e+00, -1.7778e-01],\n",
       "         [ 3.7030e-01,  1.2177e+00, -1.4297e+00,  ...,  6.7499e-01,\n",
       "          -1.3375e-01,  5.2582e-02],\n",
       "         ...,\n",
       "         [ 2.9672e-01,  9.3933e-01, -1.8115e-01,  ..., -4.1821e-01,\n",
       "          -1.3504e-01, -3.1655e-01],\n",
       "         [ 2.9225e-01,  9.3933e-01, -4.0603e-01,  ..., -2.8719e-01,\n",
       "          -1.3504e-01, -8.5010e-01],\n",
       "         [-8.1852e-01,  9.3933e-01, -6.4785e-01,  ..., -7.5491e-01,\n",
       "          -1.3504e-01, -6.8007e-01]],\n",
       "\n",
       "        [[-6.8197e-01,  3.5533e-01,  2.9951e-01,  ...,  1.8684e-01,\n",
       "           1.1379e+00, -1.8221e-01],\n",
       "         [-1.0659e+00,  2.8676e-01,  3.9293e-01,  ...,  2.0612e-01,\n",
       "           8.7881e-01,  1.3179e-01],\n",
       "         [-9.3567e-01,  1.9362e-01,  5.4992e-01,  ...,  9.4352e-01,\n",
       "           5.5305e-01,  1.8029e-02],\n",
       "         ...,\n",
       "         [ 5.6541e-02,  5.2198e-01,  4.2959e-01,  ..., -1.5588e-01,\n",
       "           1.2126e-01,  4.8665e-01],\n",
       "         [ 9.0296e-02,  5.2198e-01,  1.0414e-01,  ...,  4.0699e-02,\n",
       "           1.2126e-01,  1.1235e-01],\n",
       "         [-1.7889e-01,  5.2198e-01,  1.9348e-01,  ..., -4.7904e-02,\n",
       "           1.2126e-01,  1.2904e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m4, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10000.0\n"
     ]
    }
   ],
   "source": [
    "print(-1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
