{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/apps/userenv/beck/rwkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from wkv_kernel import WKV, WKVConfig\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the recurrence formula from CUDA to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /system/user/beck/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /system/user/beck/.cache/torch_extensions/py310_cu117/wkv/build.ninja...\n",
      "Building extension module wkv...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module wkv...\n"
     ]
    }
   ],
   "source": [
    "# Setup cuda kernel\n",
    "wkv_cuda_kernel = WKV()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input shapes from training\n",
    "batch_size = 12\n",
    "seq_len = 512\n",
    "embedding_dim = 512\n",
    "time_decay = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "time_first = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "k = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "v = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                device=device,\n",
    "                dtype=dtype).to(memory_format=torch.contiguous_format)\n",
    "y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock up for experiment\n",
    "# batch_size = 2\n",
    "# seq_len = 4\n",
    "# embedding_dim = 2\n",
    "# entries = batch_size * seq_len * embedding_dim\n",
    "# time_decay = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# time_first = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# k = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# v = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "#                 device=device).to(memory_format=torch.contiguous_format)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkv_cuda_kernel.wkv_cuda.forward(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                             time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.0614e-01, -2.7206e-02, -1.0326e+00,  ..., -8.8088e-01,\n",
       "           3.0217e-01, -1.6988e+00],\n",
       "         [-1.8448e-02,  1.9646e-01, -1.2128e+00,  ..., -8.4950e-01,\n",
       "           6.7267e-01, -1.3180e+00],\n",
       "         [ 2.3237e-01,  2.8511e-01, -1.0060e+00,  ..., -8.2239e-01,\n",
       "           1.8111e-01, -6.8774e-01],\n",
       "         ...,\n",
       "         [ 3.2317e-01, -4.1025e-02, -4.8568e-01,  ..., -1.6375e-01,\n",
       "          -1.9714e+00, -5.2361e-04],\n",
       "         [ 3.2317e-01, -2.5891e-01, -1.1748e-01,  ..., -8.4061e-01,\n",
       "           1.5993e-01, -5.0706e-01],\n",
       "         [ 3.2317e-01, -5.5133e-01, -9.9434e-02,  ..., -9.5514e-01,\n",
       "          -9.1517e-01, -7.5674e-01]],\n",
       "\n",
       "        [[-1.8561e+00,  3.2080e-01, -2.9945e+00,  ...,  8.6864e-01,\n",
       "          -7.0153e-01, -2.9329e-01],\n",
       "         [-4.4004e-01,  9.4639e-01, -1.0114e+00,  ...,  1.3411e+00,\n",
       "           5.8858e-01, -3.4078e-01],\n",
       "         [-4.7000e-01,  1.4115e-01, -1.0208e+00,  ..., -3.7792e-01,\n",
       "           7.2464e-01,  2.1679e-01],\n",
       "         ...,\n",
       "         [-1.0560e+00,  2.2149e-01, -1.3389e-01,  ...,  3.0190e-01,\n",
       "           2.2636e-01, -4.0999e-01],\n",
       "         [-1.0560e+00,  3.7913e-01, -1.4761e-01,  ...,  7.8040e-01,\n",
       "           5.7126e-01, -1.8884e-01],\n",
       "         [-1.0560e+00, -1.5165e-01,  7.1288e-01,  ...,  6.0121e-01,\n",
       "          -2.3930e-01,  3.9022e-02]],\n",
       "\n",
       "        [[ 5.6127e-01, -6.2120e-01, -1.8995e-02,  ...,  2.0433e-01,\n",
       "          -4.1559e-01,  4.6301e-01],\n",
       "         [ 2.8188e-02, -5.2809e-01, -4.1497e-01,  ...,  4.3808e-01,\n",
       "           4.7961e-01, -1.0615e+00],\n",
       "         [-5.3787e-01, -4.0426e-01, -6.2630e-01,  ...,  6.1515e-01,\n",
       "          -2.6310e-01,  9.5136e-03],\n",
       "         ...,\n",
       "         [ 2.8084e-01, -7.4786e-01,  3.0902e-01,  ..., -6.8842e-01,\n",
       "           6.0026e-01, -6.2699e-02],\n",
       "         [ 2.8084e-01, -7.8316e-01,  9.2735e-02,  ..., -9.6016e-01,\n",
       "           7.4185e-01, -6.0118e-01],\n",
       "         [ 2.8084e-01, -6.2244e-01, -6.0128e-01,  ..., -8.6743e-01,\n",
       "           1.1405e+00, -6.2976e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.9022e-01, -3.9789e-02, -1.8347e+00,  ...,  5.4681e-01,\n",
       "           4.3509e-02, -8.3520e-02],\n",
       "         [-5.8944e-01, -5.3341e-02,  6.6321e-02,  ..., -5.5700e-02,\n",
       "          -1.0085e+00,  3.3907e-01],\n",
       "         [ 3.0491e-01,  1.0254e-01, -3.8003e-01,  ..., -1.8387e-01,\n",
       "          -5.1352e-01,  1.8330e-01],\n",
       "         ...,\n",
       "         [ 1.8314e-01,  4.9604e-01,  5.3356e-02,  ...,  1.0596e+00,\n",
       "          -3.4260e-01,  1.2035e+00],\n",
       "         [ 1.8314e-01,  2.2358e-01,  8.2631e-01,  ...,  9.2217e-01,\n",
       "           1.2008e+00,  9.2872e-01],\n",
       "         [ 1.8314e-01, -1.5023e-01,  6.2866e-01,  ...,  8.1212e-01,\n",
       "          -8.1037e-01,  5.6573e-01]],\n",
       "\n",
       "        [[-8.7980e-01,  7.7461e-01, -3.4765e-01,  ...,  1.1020e-02,\n",
       "           1.5610e+00, -1.2262e-01],\n",
       "         [-6.0985e-01,  7.5666e-01, -4.5287e-01,  ..., -7.4378e-01,\n",
       "           3.6425e-01, -1.6411e+00],\n",
       "         [ 7.7439e-01,  4.4706e-01, -6.0869e-02,  ..., -6.3963e-01,\n",
       "           7.8706e-02, -1.3361e+00],\n",
       "         ...,\n",
       "         [-4.0455e-01,  8.4276e-02,  7.2326e-01,  ...,  5.2255e-01,\n",
       "          -4.4650e-01,  1.0438e+00],\n",
       "         [-4.0455e-01,  9.7172e-02,  7.7722e-01,  ...,  4.5188e-01,\n",
       "          -7.0207e-01,  9.2228e-01],\n",
       "         [-4.0455e-01, -5.3784e-01,  6.9749e-01,  ..., -9.8983e-02,\n",
       "          -2.9221e-01,  6.8018e-01]],\n",
       "\n",
       "        [[ 1.0666e+00,  1.6273e+00, -9.9908e-01,  ..., -1.4068e+00,\n",
       "          -1.4607e+00,  8.8740e-01],\n",
       "         [ 1.6899e+00,  1.4498e+00, -7.2103e-01,  ..., -1.1376e+00,\n",
       "           3.8039e-01,  9.8618e-01],\n",
       "         [ 1.2664e+00,  9.0556e-01, -4.6805e-01,  ..., -3.6550e-01,\n",
       "           3.1106e-01,  5.2570e-01],\n",
       "         ...,\n",
       "         [ 1.1457e+00,  1.4957e+00, -4.9340e-01,  ...,  3.0478e-02,\n",
       "          -2.2843e+00,  3.7510e-01],\n",
       "         [ 1.1457e+00,  1.1523e+00,  9.1098e-01,  ..., -3.3787e-01,\n",
       "          -4.5332e-01, -6.2141e-01],\n",
       "         [ 1.1457e+00,  7.1032e-01,  1.6886e-02,  ..., -3.5194e-01,\n",
       "          -1.7295e+00, -1.3941e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduced torch version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT output:\n",
    "\n",
    "# ww = u_timefirst[c] + k[b, i, c]\n",
    "# p = max(pp, ww)\n",
    "# e1 = exp(pp - p)\n",
    "# e2 = exp(ww - p)\n",
    "# y[b, i, c] = (e1 * aa + e2 * v[b, i, c]) / (e1 * bb + e2)\n",
    "# ww = w_timedecay[c] + pp\n",
    "# p = max(ww, k[b, i, c])\n",
    "# e1 = exp(ww - p)\n",
    "# e2 = exp(k[b, i, c] - p)\n",
    "# aa = e1 * aa + e2 * v[b, i, c]\n",
    "# bb = e1 * bb + e2\n",
    "# pp = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    for b in range(batch_size):\n",
    "        for c in range(embedding_dim):\n",
    "            pp = MIN_VAL\n",
    "            aa = 0\n",
    "            bb = 0\n",
    "            for i in range(seq_len):\n",
    "                # ii = i * embedding_dim + c\n",
    "                kk = k[b, i, c]\n",
    "                vv = v[b, i, c]\n",
    "                ww = time_first[c] + kk\n",
    "                p = torch.tensor(max(pp, ww))\n",
    "                e1 = torch.exp(pp - p)\n",
    "                e2 = torch.exp(ww - p)\n",
    "                new_y = (e1 * aa + e2 * vv) / (e1 * bb + e2)\n",
    "                y[b, i, c] = new_y\n",
    "                ww = time_decay[c] + pp\n",
    "                p = torch.tensor(max(ww, kk))\n",
    "                e1 = torch.exp(ww - p)\n",
    "                e2 = torch.exp(kk - p) # uses current key\n",
    "                aa = e1 * aa + e2 * vv\n",
    "                bb = e1 * bb + e2\n",
    "                pp = p\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_m = cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "#                         time_first, k, v, y)\n",
    "# y_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v3 (own impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    for t in range(seq_len):\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m3 = cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.0614e-01, -2.7206e-02, -1.0326e+00,  ..., -8.8088e-01,\n",
       "           3.0217e-01, -1.6988e+00],\n",
       "         [-1.8448e-02,  1.9646e-01, -1.2128e+00,  ..., -8.4950e-01,\n",
       "           6.7267e-01, -1.3180e+00],\n",
       "         [ 2.3237e-01,  2.8511e-01, -1.0060e+00,  ..., -8.2239e-01,\n",
       "           1.8111e-01, -6.8774e-01],\n",
       "         ...,\n",
       "         [ 3.2317e-01, -4.1025e-02, -4.8568e-01,  ..., -1.6375e-01,\n",
       "          -1.9714e+00, -5.2361e-04],\n",
       "         [ 3.2317e-01, -2.5891e-01, -1.1748e-01,  ..., -8.4061e-01,\n",
       "           1.5993e-01, -5.0706e-01],\n",
       "         [ 3.2317e-01, -5.5133e-01, -9.9434e-02,  ..., -9.5514e-01,\n",
       "          -9.1517e-01, -7.5674e-01]],\n",
       "\n",
       "        [[-1.8561e+00,  3.2080e-01, -2.9945e+00,  ...,  8.6864e-01,\n",
       "          -7.0153e-01, -2.9329e-01],\n",
       "         [-4.4004e-01,  9.4639e-01, -1.0114e+00,  ...,  1.3411e+00,\n",
       "           5.8858e-01, -3.4078e-01],\n",
       "         [-4.7000e-01,  1.4115e-01, -1.0208e+00,  ..., -3.7792e-01,\n",
       "           7.2464e-01,  2.1679e-01],\n",
       "         ...,\n",
       "         [-1.0560e+00,  2.2149e-01, -1.3389e-01,  ...,  3.0190e-01,\n",
       "           2.2636e-01, -4.0999e-01],\n",
       "         [-1.0560e+00,  3.7913e-01, -1.4761e-01,  ...,  7.8040e-01,\n",
       "           5.7126e-01, -1.8884e-01],\n",
       "         [-1.0560e+00, -1.5165e-01,  7.1288e-01,  ...,  6.0121e-01,\n",
       "          -2.3930e-01,  3.9022e-02]],\n",
       "\n",
       "        [[ 5.6127e-01, -6.2120e-01, -1.8995e-02,  ...,  2.0433e-01,\n",
       "          -4.1559e-01,  4.6301e-01],\n",
       "         [ 2.8188e-02, -5.2809e-01, -4.1497e-01,  ...,  4.3808e-01,\n",
       "           4.7961e-01, -1.0615e+00],\n",
       "         [-5.3787e-01, -4.0426e-01, -6.2630e-01,  ...,  6.1515e-01,\n",
       "          -2.6310e-01,  9.5136e-03],\n",
       "         ...,\n",
       "         [ 2.8084e-01, -7.4786e-01,  3.0902e-01,  ..., -6.8842e-01,\n",
       "           6.0026e-01, -6.2699e-02],\n",
       "         [ 2.8084e-01, -7.8316e-01,  9.2735e-02,  ..., -9.6016e-01,\n",
       "           7.4185e-01, -6.0118e-01],\n",
       "         [ 2.8084e-01, -6.2244e-01, -6.0128e-01,  ..., -8.6743e-01,\n",
       "           1.1405e+00, -6.2976e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.9022e-01, -3.9789e-02, -1.8347e+00,  ...,  5.4681e-01,\n",
       "           4.3509e-02, -8.3520e-02],\n",
       "         [-5.8944e-01, -5.3341e-02,  6.6321e-02,  ..., -5.5700e-02,\n",
       "          -1.0085e+00,  3.3907e-01],\n",
       "         [ 3.0491e-01,  1.0254e-01, -3.8003e-01,  ..., -1.8387e-01,\n",
       "          -5.1352e-01,  1.8330e-01],\n",
       "         ...,\n",
       "         [ 1.8314e-01,  4.9604e-01,  5.3356e-02,  ...,  1.0596e+00,\n",
       "          -3.4260e-01,  1.2035e+00],\n",
       "         [ 1.8314e-01,  2.2358e-01,  8.2631e-01,  ...,  9.2217e-01,\n",
       "           1.2008e+00,  9.2872e-01],\n",
       "         [ 1.8314e-01, -1.5023e-01,  6.2866e-01,  ...,  8.1212e-01,\n",
       "          -8.1037e-01,  5.6573e-01]],\n",
       "\n",
       "        [[-8.7980e-01,  7.7461e-01, -3.4765e-01,  ...,  1.1020e-02,\n",
       "           1.5610e+00, -1.2262e-01],\n",
       "         [-6.0985e-01,  7.5666e-01, -4.5287e-01,  ..., -7.4378e-01,\n",
       "           3.6425e-01, -1.6411e+00],\n",
       "         [ 7.7439e-01,  4.4706e-01, -6.0869e-02,  ..., -6.3963e-01,\n",
       "           7.8706e-02, -1.3361e+00],\n",
       "         ...,\n",
       "         [-4.0455e-01,  8.4276e-02,  7.2326e-01,  ...,  5.2255e-01,\n",
       "          -4.4650e-01,  1.0438e+00],\n",
       "         [-4.0455e-01,  9.7172e-02,  7.7722e-01,  ...,  4.5188e-01,\n",
       "          -7.0207e-01,  9.2228e-01],\n",
       "         [-4.0455e-01, -5.3784e-01,  6.9749e-01,  ..., -9.8983e-02,\n",
       "          -2.9221e-01,  6.8018e-01]],\n",
       "\n",
       "        [[ 1.0666e+00,  1.6273e+00, -9.9908e-01,  ..., -1.4068e+00,\n",
       "          -1.4607e+00,  8.8740e-01],\n",
       "         [ 1.6899e+00,  1.4498e+00, -7.2103e-01,  ..., -1.1376e+00,\n",
       "           3.8039e-01,  9.8618e-01],\n",
       "         [ 1.2664e+00,  9.0556e-01, -4.6805e-01,  ..., -3.6550e-01,\n",
       "           3.1106e-01,  5.2570e-01],\n",
       "         ...,\n",
       "         [ 1.1457e+00,  1.4957e+00, -4.9340e-01,  ...,  3.0478e-02,\n",
       "          -2.2843e+00,  3.7510e-01],\n",
       "         [ 1.1457e+00,  1.1523e+00,  9.1098e-01,  ..., -3.3787e-01,\n",
       "          -4.5332e-01, -6.2141e-01],\n",
       "         [ 1.1457e+00,  7.1032e-01,  1.6886e-02,  ..., -3.5194e-01,\n",
       "          -1.7295e+00, -1.3941e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m3, atol=1e-6)), print(torch.allclose(y_gt, y_m3, atol=1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6061, -0.0272],\n",
       "          [-0.0184,  0.1965]],\n",
       " \n",
       "         [[-1.8561,  0.3208],\n",
       "          [-0.4400,  0.9464]]], device='cuda:0'),\n",
       " tensor([[[ 0.6061, -0.0272],\n",
       "          [-0.0184,  0.1965]],\n",
       " \n",
       "         [[-1.8561,  0.3208],\n",
       "          [-0.4400,  0.9464]]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt[:2, :2, :2], y_m3[:2, :2, :2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v4 (simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = 0.0 #-1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    eps = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    \n",
    "    for t in range(seq_len):\n",
    "        #! v1\n",
    "        # y_[t] = (aa + v_[t] * torch.exp(tf + k_[t]-eps)) / (bb + torch.exp(tf + k_[t]-eps))\n",
    "        # eps_next = torch.max(td+eps, k_[t])\n",
    "\n",
    "        # aa = (aa * torch.exp(td+eps-eps_next) + v_[t] * torch.exp(k_[t]-eps_next))\n",
    "        # bb = (bb * torch.exp(td+eps-eps_next) + torch.exp(k_[t]-eps_next))\n",
    "        # eps = eps_next\n",
    "\n",
    "        #! v2\n",
    "        e_tf_k = torch.exp(tf + k_[t] - eps)\n",
    "        y_[t] = (aa + v_[t] * e_tf_k) / (bb + e_tf_k)\n",
    "        eps_next = torch.max(td+eps, k_[t])\n",
    "\n",
    "        e_td_k = torch.exp(td+eps-eps_next)\n",
    "        e_k = torch.exp(k_[t]-eps_next)\n",
    "        aa = (aa * e_td_k + v_[t] * e_k)\n",
    "        bb = (bb * e_td_k + e_k)\n",
    "        eps = eps_next\n",
    "\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m4 = cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.0614e-01, -2.7206e-02, -1.0326e+00,  ..., -8.8088e-01,\n",
       "           3.0217e-01, -1.6988e+00],\n",
       "         [-1.8448e-02,  1.9646e-01, -1.2128e+00,  ..., -8.4950e-01,\n",
       "           6.7267e-01, -1.3180e+00],\n",
       "         [ 2.3237e-01,  2.8511e-01, -1.0060e+00,  ..., -8.2239e-01,\n",
       "           1.8111e-01, -6.8774e-01],\n",
       "         ...,\n",
       "         [ 3.2317e-01, -4.1025e-02, -4.8568e-01,  ..., -1.6375e-01,\n",
       "          -1.9714e+00, -5.2361e-04],\n",
       "         [ 3.2317e-01, -2.5891e-01, -1.1748e-01,  ..., -8.4061e-01,\n",
       "           1.5993e-01, -5.0706e-01],\n",
       "         [ 3.2317e-01, -5.5133e-01, -9.9434e-02,  ..., -9.5514e-01,\n",
       "          -9.1517e-01, -7.5674e-01]],\n",
       "\n",
       "        [[-1.8561e+00,  3.2080e-01, -2.9945e+00,  ...,  8.6864e-01,\n",
       "          -7.0153e-01, -2.9329e-01],\n",
       "         [-4.4004e-01,  9.4639e-01, -1.0114e+00,  ...,  1.3411e+00,\n",
       "           5.8858e-01, -3.4078e-01],\n",
       "         [-4.7000e-01,  1.4115e-01, -1.0208e+00,  ..., -3.7792e-01,\n",
       "           7.2464e-01,  2.1679e-01],\n",
       "         ...,\n",
       "         [-1.0560e+00,  2.2149e-01, -1.3389e-01,  ...,  3.0190e-01,\n",
       "           2.2636e-01, -4.0999e-01],\n",
       "         [-1.0560e+00,  3.7913e-01, -1.4761e-01,  ...,  7.8040e-01,\n",
       "           5.7126e-01, -1.8884e-01],\n",
       "         [-1.0560e+00, -1.5165e-01,  7.1288e-01,  ...,  6.0121e-01,\n",
       "          -2.3930e-01,  3.9022e-02]],\n",
       "\n",
       "        [[ 5.6127e-01, -6.2120e-01, -1.8995e-02,  ...,  2.0433e-01,\n",
       "          -4.1559e-01,  4.6301e-01],\n",
       "         [ 2.8188e-02, -5.2809e-01, -4.1497e-01,  ...,  4.3808e-01,\n",
       "           4.7961e-01, -1.0615e+00],\n",
       "         [-5.3787e-01, -4.0426e-01, -6.2630e-01,  ...,  6.1515e-01,\n",
       "          -2.6310e-01,  9.5136e-03],\n",
       "         ...,\n",
       "         [ 2.8084e-01, -7.4786e-01,  3.0902e-01,  ..., -6.8842e-01,\n",
       "           6.0026e-01, -6.2699e-02],\n",
       "         [ 2.8084e-01, -7.8316e-01,  9.2735e-02,  ..., -9.6016e-01,\n",
       "           7.4185e-01, -6.0118e-01],\n",
       "         [ 2.8084e-01, -6.2244e-01, -6.0128e-01,  ..., -8.6743e-01,\n",
       "           1.1405e+00, -6.2976e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.9022e-01, -3.9789e-02, -1.8347e+00,  ...,  5.4681e-01,\n",
       "           4.3509e-02, -8.3520e-02],\n",
       "         [-5.8944e-01, -5.3341e-02,  6.6321e-02,  ..., -5.5700e-02,\n",
       "          -1.0085e+00,  3.3907e-01],\n",
       "         [ 3.0491e-01,  1.0254e-01, -3.8003e-01,  ..., -1.8387e-01,\n",
       "          -5.1352e-01,  1.8330e-01],\n",
       "         ...,\n",
       "         [ 1.8314e-01,  4.9604e-01,  5.3356e-02,  ...,  1.0596e+00,\n",
       "          -3.4260e-01,  1.2035e+00],\n",
       "         [ 1.8314e-01,  2.2358e-01,  8.2631e-01,  ...,  9.2217e-01,\n",
       "           1.2008e+00,  9.2872e-01],\n",
       "         [ 1.8314e-01, -1.5023e-01,  6.2866e-01,  ...,  8.1212e-01,\n",
       "          -8.1037e-01,  5.6573e-01]],\n",
       "\n",
       "        [[-8.7980e-01,  7.7461e-01, -3.4765e-01,  ...,  1.1020e-02,\n",
       "           1.5610e+00, -1.2262e-01],\n",
       "         [-6.0985e-01,  7.5666e-01, -4.5287e-01,  ..., -7.4378e-01,\n",
       "           3.6425e-01, -1.6411e+00],\n",
       "         [ 7.7439e-01,  4.4706e-01, -6.0869e-02,  ..., -6.3963e-01,\n",
       "           7.8706e-02, -1.3361e+00],\n",
       "         ...,\n",
       "         [-4.0455e-01,  8.4276e-02,  7.2326e-01,  ...,  5.2255e-01,\n",
       "          -4.4650e-01,  1.0438e+00],\n",
       "         [-4.0455e-01,  9.7172e-02,  7.7722e-01,  ...,  4.5188e-01,\n",
       "          -7.0207e-01,  9.2228e-01],\n",
       "         [-4.0455e-01, -5.3784e-01,  6.9749e-01,  ..., -9.8983e-02,\n",
       "          -2.9221e-01,  6.8018e-01]],\n",
       "\n",
       "        [[ 1.0666e+00,  1.6273e+00, -9.9908e-01,  ..., -1.4068e+00,\n",
       "          -1.4607e+00,  8.8740e-01],\n",
       "         [ 1.6899e+00,  1.4498e+00, -7.2103e-01,  ..., -1.1376e+00,\n",
       "           3.8039e-01,  9.8618e-01],\n",
       "         [ 1.2664e+00,  9.0556e-01, -4.6805e-01,  ..., -3.6550e-01,\n",
       "           3.1106e-01,  5.2570e-01],\n",
       "         ...,\n",
       "         [ 1.1457e+00,  1.4957e+00, -4.9340e-01,  ...,  3.0478e-02,\n",
       "          -2.2843e+00,  3.7510e-01],\n",
       "         [ 1.1457e+00,  1.1523e+00,  9.1098e-01,  ..., -3.3787e-01,\n",
       "          -4.5332e-01, -6.2141e-01],\n",
       "         [ 1.1457e+00,  7.1032e-01,  1.6886e-02,  ..., -3.5194e-01,\n",
       "          -1.7295e+00, -1.3941e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m4, atol=1e-6), y_m4.isnan().any(), y_gt.isnan().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
