{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/apps/userenv/beck/rwkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from wkv_kernel import WKV, WKVConfig\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the recurrence formula from CUDA to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /system/user/beck/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /system/user/beck/.cache/torch_extensions/py310_cu117/wkv/build.ninja...\n",
      "Building extension module wkv...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module wkv...\n"
     ]
    }
   ],
   "source": [
    "# Setup cuda kernel\n",
    "wkv_cuda_kernel = WKV()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input shapes from training\n",
    "batch_size = 12\n",
    "seq_len = 512\n",
    "embedding_dim = 512\n",
    "time_decay = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "time_first = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "k = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "v = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                device=device,\n",
    "                dtype=dtype).to(memory_format=torch.contiguous_format)\n",
    "y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock up for experiment\n",
    "# batch_size = 2\n",
    "# seq_len = 4\n",
    "# embedding_dim = 2\n",
    "# entries = batch_size * seq_len * embedding_dim\n",
    "# time_decay = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# time_first = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# k = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# v = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "#                 device=device).to(memory_format=torch.contiguous_format)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkv_cuda_kernel.wkv_cuda.forward(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                             time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0534, -0.3219,  0.6274,  ...,  0.3324, -0.6062, -0.2180],\n",
       "         [ 1.9780, -0.2207,  0.4891,  ...,  0.6034, -0.3334, -0.5567],\n",
       "         [ 1.5262, -0.1409,  0.4524,  ...,  0.8996,  0.3577, -0.2522],\n",
       "         ...,\n",
       "         [ 0.6318, -0.2448, -0.3052,  ...,  0.4673, -1.2484, -0.0291],\n",
       "         [ 0.4366, -0.2448, -0.8811,  ...,  0.4521, -1.2866, -0.0023],\n",
       "         [ 0.3315, -0.2448,  0.1401,  ...,  0.4907, -0.7423,  0.0164]],\n",
       "\n",
       "        [[-0.7355, -1.9907, -0.1692,  ...,  0.7174,  0.3276,  1.3929],\n",
       "         [-0.6438, -0.0233,  0.2341,  ..., -0.0680, -0.5767,  0.1555],\n",
       "         [-0.1367, -2.1636, -1.1826,  ...,  0.3415,  1.3689,  0.1871],\n",
       "         ...,\n",
       "         [ 0.3206, -1.5454,  1.0111,  ...,  0.1211,  0.8732, -0.7091],\n",
       "         [ 0.8627, -1.5454,  0.4594,  ..., -0.0901,  1.2090, -0.6461],\n",
       "         [ 0.6551, -1.5454,  0.1613,  ..., -0.3871,  0.4103, -0.6684]],\n",
       "\n",
       "        [[-1.2690, -0.3401, -1.9859,  ..., -1.4925,  1.9849, -0.9622],\n",
       "         [-0.6077, -0.3963, -1.0200,  ..., -1.3491, -1.8690, -0.6226],\n",
       "         [-0.0187, -0.4973, -0.2043,  ..., -0.4300, -1.7776, -0.5622],\n",
       "         ...,\n",
       "         [ 0.4444, -0.3798,  0.2405,  ..., -1.2205,  0.1051, -0.0622],\n",
       "         [ 0.4901, -0.3798, -0.4259,  ..., -1.2928,  0.1858, -0.1291],\n",
       "         [ 0.1457, -0.3798,  0.0539,  ..., -1.2597, -0.2780, -0.1492]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0942, -1.5609,  1.8374,  ..., -1.4207,  0.1462,  1.2150],\n",
       "         [-0.2361, -0.7580,  0.6743,  ...,  0.5150,  0.4158,  1.2331],\n",
       "         [-0.7210,  0.0862,  0.2444,  ...,  0.3514,  0.2916, -0.7560],\n",
       "         ...,\n",
       "         [-0.2515, -0.8395,  0.4128,  ...,  0.0979, -0.3625,  0.1001],\n",
       "         [-0.3678, -0.8395, -0.6782,  ...,  0.7151,  0.9042,  0.1729],\n",
       "         [-0.1284, -0.8395, -1.2616,  ...,  0.7142,  0.2600,  0.1267]],\n",
       "\n",
       "        [[-0.2437, -0.1798,  1.1215,  ...,  0.1854, -0.2632, -1.1416],\n",
       "         [-0.3788,  0.7076,  0.5477,  ..., -0.6178,  0.1119, -0.5938],\n",
       "         [-0.5450,  0.2921, -0.0320,  ..., -0.6138, -1.6635, -1.1732],\n",
       "         ...,\n",
       "         [-0.7097,  0.2683, -0.7905,  ...,  0.2765, -0.5020,  0.1763],\n",
       "         [-0.3959,  0.2683, -0.4692,  ...,  0.3920, -0.4596,  0.2618],\n",
       "         [-0.0129,  0.2683, -0.6270,  ...,  0.4415, -0.7082,  0.2749]],\n",
       "\n",
       "        [[-1.0368, -0.5081,  0.8477,  ..., -1.8714,  0.1424, -0.1470],\n",
       "         [-0.9482, -0.5532,  0.5041,  ..., -0.5999,  0.0929, -0.0281],\n",
       "         [-0.5483, -0.9052,  0.2438,  ..., -0.3840, -0.2808, -0.2429],\n",
       "         ...,\n",
       "         [ 0.3552, -0.5951,  0.9848,  ...,  0.5223, -1.0968,  0.1751],\n",
       "         [-0.2416, -0.5951,  0.5898,  ...,  0.5415, -1.3201,  0.2208],\n",
       "         [-0.0206, -0.5951,  0.7544,  ...,  0.4885, -0.1632,  0.0159]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduced torch version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT output:\n",
    "\n",
    "# ww = u_timefirst[c] + k[b, i, c]\n",
    "# p = max(pp, ww)\n",
    "# e1 = exp(pp - p)\n",
    "# e2 = exp(ww - p)\n",
    "# y[b, i, c] = (e1 * aa + e2 * v[b, i, c]) / (e1 * bb + e2)\n",
    "# ww = w_timedecay[c] + pp\n",
    "# p = max(ww, k[b, i, c])\n",
    "# e1 = exp(ww - p)\n",
    "# e2 = exp(k[b, i, c] - p)\n",
    "# aa = e1 * aa + e2 * v[b, i, c]\n",
    "# bb = e1 * bb + e2\n",
    "# pp = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    for b in range(batch_size):\n",
    "        for c in range(embedding_dim):\n",
    "            pp = MIN_VAL\n",
    "            aa = 0\n",
    "            bb = 0\n",
    "            for i in range(seq_len):\n",
    "                # ii = i * embedding_dim + c\n",
    "                kk = k[b, i, c]\n",
    "                vv = v[b, i, c]\n",
    "                ww = time_first[c] + kk\n",
    "                p = torch.tensor(max(pp, ww))\n",
    "                e1 = torch.exp(pp - p)\n",
    "                e2 = torch.exp(ww - p)\n",
    "                new_y = (e1 * aa + e2 * vv) / (e1 * bb + e2)\n",
    "                y[b, i, c] = new_y\n",
    "                ww = time_decay[c] + pp\n",
    "                p = torch.tensor(max(ww, kk))\n",
    "                e1 = torch.exp(ww - p)\n",
    "                e2 = torch.exp(kk - p) # uses current key\n",
    "                aa = e1 * aa + e2 * vv\n",
    "                bb = e1 * bb + e2\n",
    "                pp = p\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_m = cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "#                         time_first, k, v, y)\n",
    "# y_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v3 (own impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    for t in range(seq_len):\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m3 = cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0534, -0.3219,  0.6274,  ...,  0.3324, -0.6062, -0.2180],\n",
       "         [ 1.9780, -0.2207,  0.4891,  ...,  0.6034, -0.3334, -0.5567],\n",
       "         [ 1.5262, -0.1409,  0.4524,  ...,  0.8996,  0.3577, -0.2522],\n",
       "         ...,\n",
       "         [ 0.6318, -0.2448, -0.3052,  ...,  0.4673, -1.2484, -0.0291],\n",
       "         [ 0.4366, -0.2448, -0.8811,  ...,  0.4521, -1.2866, -0.0023],\n",
       "         [ 0.3315, -0.2448,  0.1401,  ...,  0.4907, -0.7423,  0.0164]],\n",
       "\n",
       "        [[-0.7355, -1.9907, -0.1692,  ...,  0.7174,  0.3276,  1.3929],\n",
       "         [-0.6438, -0.0233,  0.2341,  ..., -0.0680, -0.5767,  0.1555],\n",
       "         [-0.1367, -2.1636, -1.1826,  ...,  0.3415,  1.3689,  0.1871],\n",
       "         ...,\n",
       "         [ 0.3206, -1.5454,  1.0111,  ...,  0.1211,  0.8732, -0.7091],\n",
       "         [ 0.8627, -1.5454,  0.4594,  ..., -0.0901,  1.2090, -0.6461],\n",
       "         [ 0.6551, -1.5454,  0.1613,  ..., -0.3871,  0.4103, -0.6684]],\n",
       "\n",
       "        [[-1.2690, -0.3401, -1.9859,  ..., -1.4925,  1.9849, -0.9622],\n",
       "         [-0.6077, -0.3963, -1.0200,  ..., -1.3491, -1.8690, -0.6226],\n",
       "         [-0.0187, -0.4973, -0.2043,  ..., -0.4300, -1.7776, -0.5622],\n",
       "         ...,\n",
       "         [ 0.4444, -0.3798,  0.2405,  ..., -1.2205,  0.1051, -0.0622],\n",
       "         [ 0.4901, -0.3798, -0.4259,  ..., -1.2928,  0.1858, -0.1291],\n",
       "         [ 0.1457, -0.3798,  0.0539,  ..., -1.2597, -0.2780, -0.1492]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0942, -1.5609,  1.8374,  ..., -1.4207,  0.1462,  1.2150],\n",
       "         [-0.2361, -0.7580,  0.6743,  ...,  0.5150,  0.4158,  1.2331],\n",
       "         [-0.7210,  0.0862,  0.2444,  ...,  0.3514,  0.2916, -0.7560],\n",
       "         ...,\n",
       "         [-0.2515, -0.8395,  0.4128,  ...,  0.0979, -0.3625,  0.1001],\n",
       "         [-0.3678, -0.8395, -0.6782,  ...,  0.7151,  0.9042,  0.1729],\n",
       "         [-0.1284, -0.8395, -1.2616,  ...,  0.7142,  0.2600,  0.1267]],\n",
       "\n",
       "        [[-0.2437, -0.1798,  1.1215,  ...,  0.1854, -0.2632, -1.1416],\n",
       "         [-0.3788,  0.7076,  0.5477,  ..., -0.6178,  0.1119, -0.5938],\n",
       "         [-0.5450,  0.2921, -0.0320,  ..., -0.6138, -1.6635, -1.1732],\n",
       "         ...,\n",
       "         [-0.7097,  0.2683, -0.7905,  ...,  0.2765, -0.5020,  0.1763],\n",
       "         [-0.3959,  0.2683, -0.4692,  ...,  0.3920, -0.4596,  0.2618],\n",
       "         [-0.0129,  0.2683, -0.6270,  ...,  0.4415, -0.7082,  0.2749]],\n",
       "\n",
       "        [[-1.0368, -0.5081,  0.8477,  ..., -1.8714,  0.1424, -0.1470],\n",
       "         [-0.9482, -0.5532,  0.5041,  ..., -0.5999,  0.0929, -0.0281],\n",
       "         [-0.5483, -0.9052,  0.2438,  ..., -0.3840, -0.2808, -0.2429],\n",
       "         ...,\n",
       "         [ 0.3552, -0.5951,  0.9848,  ...,  0.5223, -1.0968,  0.1751],\n",
       "         [-0.2416, -0.5951,  0.5898,  ...,  0.5415, -1.3201,  0.2208],\n",
       "         [-0.0206, -0.5951,  0.7544,  ...,  0.4885, -0.1632,  0.0159]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m3, atol=1e-6)), print(torch.allclose(y_gt, y_m3, atol=1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.0534, -0.3219],\n",
       "          [ 1.9780, -0.2207]],\n",
       " \n",
       "         [[-0.7355, -1.9907],\n",
       "          [-0.6438, -0.0233]]], device='cuda:0'),\n",
       " tensor([[[ 2.0534, -0.3219],\n",
       "          [ 1.9780, -0.2207]],\n",
       " \n",
       "         [[-0.7355, -1.9907],\n",
       "          [-0.6438, -0.0233]]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt[:2, :2, :2], y_m3[:2, :2, :2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single computation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "            device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 512, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape, v.shape, y.shape, time_decay.shape, time_first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = rearrange(k, 'b s e -> s b e')\n",
    "v_ = rearrange(v, 'b s e -> s b e')\n",
    "y_ = rearrange(y, 'b s e -> s b e')\n",
    "tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "td = repeat(time_decay, 'e -> b e', b=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 12, 512]),\n",
       " torch.Size([512, 12, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512]),\n",
       " torch.Size([12, 512]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_.shape, v_.shape, y.shape, td.shape, tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_VAL = -1e-38\n",
    "aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = tf + k_[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(pp, ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(pp - p)\n",
    "e2 = torch.exp(ww - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = td + pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6083,  1.0452, -1.0215,  ..., -0.2204, -0.9684, -0.0350],\n",
       "        [-0.6083,  1.0452, -1.0215,  ..., -0.2204, -0.9684, -0.0350],\n",
       "        [-0.6083,  1.0452, -1.0215,  ..., -0.2204, -0.9684, -0.0350],\n",
       "        ...,\n",
       "        [-0.6083,  1.0452, -1.0215,  ..., -0.2204, -0.9684, -0.0350],\n",
       "        [-0.6083,  1.0452, -1.0215,  ..., -0.2204, -0.9684, -0.0350],\n",
       "        [-0.6083,  1.0452, -1.0215,  ..., -0.2204, -0.9684, -0.0350]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(ww, k_[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(ww - p)\n",
    "e2 = torch.exp(k_[t] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = e1 * aa + e2 * v_[t]\n",
    "bb = e1 * bb + e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v4 (own impl, simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    # debug metrics\n",
    "    max_pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_pp = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    max_aa = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_aa = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    max_bb = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    min_bb = torch.full((batch_size, embedding_dim), -MIN_VAL, dtype=dtype, device=device)\n",
    "    eps = pp\n",
    "    for t in range(seq_len):\n",
    "        # #! original version\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "\n",
    "        # #? debug metrics\n",
    "        max_pp = torch.max(max_pp, pp)\n",
    "        min_pp = torch.min(min_pp, pp)\n",
    "        max_aa = torch.max(max_aa, aa)\n",
    "        min_aa = torch.min(min_aa, aa)\n",
    "        max_bb = torch.max(max_bb, bb)\n",
    "        min_bb = torch.min(min_bb, bb)\n",
    "\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y, {'max_pp': max_pp, 'min_pp': min_pp, 'max_aa': max_aa, 'min_aa': min_aa, 'max_bb': max_bb, 'min_bb': min_bb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m4, ret_dict = cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0534, -0.3219,  0.6274,  ...,  0.3324, -0.6062, -0.2180],\n",
       "         [ 1.9780, -0.2207,  0.4891,  ...,  0.6034, -0.3334, -0.5567],\n",
       "         [ 1.5262, -0.1409,  0.4524,  ...,  0.8996,  0.3577, -0.2522],\n",
       "         ...,\n",
       "         [ 0.6318, -0.2448, -0.3052,  ...,  0.4673, -1.2484, -0.0291],\n",
       "         [ 0.4366, -0.2448, -0.8811,  ...,  0.4521, -1.2866, -0.0023],\n",
       "         [ 0.3315, -0.2448,  0.1401,  ...,  0.4907, -0.7423,  0.0164]],\n",
       "\n",
       "        [[-0.7355, -1.9907, -0.1692,  ...,  0.7174,  0.3276,  1.3929],\n",
       "         [-0.6438, -0.0233,  0.2341,  ..., -0.0680, -0.5767,  0.1555],\n",
       "         [-0.1367, -2.1636, -1.1826,  ...,  0.3415,  1.3689,  0.1871],\n",
       "         ...,\n",
       "         [ 0.3206, -1.5454,  1.0111,  ...,  0.1211,  0.8732, -0.7091],\n",
       "         [ 0.8627, -1.5454,  0.4594,  ..., -0.0901,  1.2090, -0.6461],\n",
       "         [ 0.6551, -1.5454,  0.1613,  ..., -0.3871,  0.4103, -0.6684]],\n",
       "\n",
       "        [[-1.2690, -0.3401, -1.9859,  ..., -1.4925,  1.9849, -0.9622],\n",
       "         [-0.6077, -0.3963, -1.0200,  ..., -1.3491, -1.8690, -0.6226],\n",
       "         [-0.0187, -0.4973, -0.2043,  ..., -0.4300, -1.7776, -0.5622],\n",
       "         ...,\n",
       "         [ 0.4444, -0.3798,  0.2405,  ..., -1.2205,  0.1051, -0.0622],\n",
       "         [ 0.4901, -0.3798, -0.4259,  ..., -1.2928,  0.1858, -0.1291],\n",
       "         [ 0.1457, -0.3798,  0.0539,  ..., -1.2597, -0.2780, -0.1492]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0942, -1.5609,  1.8374,  ..., -1.4207,  0.1462,  1.2150],\n",
       "         [-0.2361, -0.7580,  0.6743,  ...,  0.5150,  0.4158,  1.2331],\n",
       "         [-0.7210,  0.0862,  0.2444,  ...,  0.3514,  0.2916, -0.7560],\n",
       "         ...,\n",
       "         [-0.2515, -0.8395,  0.4128,  ...,  0.0979, -0.3625,  0.1001],\n",
       "         [-0.3678, -0.8395, -0.6782,  ...,  0.7151,  0.9042,  0.1729],\n",
       "         [-0.1284, -0.8395, -1.2616,  ...,  0.7142,  0.2600,  0.1267]],\n",
       "\n",
       "        [[-0.2437, -0.1798,  1.1215,  ...,  0.1854, -0.2632, -1.1416],\n",
       "         [-0.3788,  0.7076,  0.5477,  ..., -0.6178,  0.1119, -0.5938],\n",
       "         [-0.5450,  0.2921, -0.0320,  ..., -0.6138, -1.6635, -1.1732],\n",
       "         ...,\n",
       "         [-0.7097,  0.2683, -0.7905,  ...,  0.2765, -0.5020,  0.1763],\n",
       "         [-0.3959,  0.2683, -0.4692,  ...,  0.3920, -0.4596,  0.2618],\n",
       "         [-0.0129,  0.2683, -0.6270,  ...,  0.4415, -0.7082,  0.2749]],\n",
       "\n",
       "        [[-1.0368, -0.5081,  0.8477,  ..., -1.8714,  0.1424, -0.1470],\n",
       "         [-0.9482, -0.5532,  0.5041,  ..., -0.5999,  0.0929, -0.0281],\n",
       "         [-0.5483, -0.9052,  0.2438,  ..., -0.3840, -0.2808, -0.2429],\n",
       "         ...,\n",
       "         [ 0.3552, -0.5951,  0.9848,  ...,  0.5223, -1.0968,  0.1751],\n",
       "         [-0.2416, -0.5951,  0.5898,  ...,  0.5415, -1.3201,  0.2208],\n",
       "         [-0.0206, -0.5951,  0.7544,  ...,  0.4885, -0.1632,  0.0159]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m4, atol=1e-6), y_m4.isnan().any(), y_gt.isnan().any())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at max and min values of running sums\n",
    "In each step we use elementwise max/min operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.6918, 535.4303,   3.0462,  ...,   3.2541,   2.7332,   2.6890],\n",
       "        [  2.7069, 532.7648,   2.7629,  ...,   2.8708,   2.9609,   2.6649],\n",
       "        [  3.1108, 534.8326,   2.8436,  ...,   2.6370,   2.5693,   2.6927],\n",
       "        ...,\n",
       "        [  3.1068, 534.5170,   2.8399,  ...,   2.7139,   3.0000,   3.8625],\n",
       "        [  3.9813, 533.0916,   2.6091,  ...,   3.0547,   3.5176,   3.2510],\n",
       "        [  4.3635, 533.9435,   3.2308,  ...,   2.5703,   3.4670,   2.8087]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['max_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4057,  1.3498, -1.9416,  ..., -1.7547, -2.2083, -0.8776],\n",
       "        [-1.5637, -1.6223, -2.3486,  ..., -1.0157, -2.5531, -0.4632],\n",
       "        [-1.5771,  0.7520, -2.1367,  ..., -0.7678, -2.0311,  0.5119],\n",
       "        ...,\n",
       "        [-1.6594,  0.4364, -1.8841,  ..., -0.8170, -2.0275, -0.0373],\n",
       "        [-1.3813, -0.9890, -1.9632,  ..., -0.4885, -1.8539, -0.1139],\n",
       "        [-1.5046, -0.1371, -1.6838,  ..., -0.6645, -1.4663,  0.4953]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['min_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.5843, -0.2627,  3.3414,  ...,  4.5563,  3.1521,  2.5759],\n",
       "         [ 3.7239, -1.3365,  2.7194,  ...,  4.4296,  4.1109,  4.9951],\n",
       "         [ 3.6726, -0.3401,  2.9561,  ...,  3.6110,  2.8570,  4.5387],\n",
       "         ...,\n",
       "         [ 3.2468, -1.0790,  3.5646,  ...,  6.2724,  3.1855,  4.2919],\n",
       "         [ 4.0605,  0.6280,  4.0908,  ...,  5.7543,  2.9985,  4.3112],\n",
       "         [ 3.9596, -0.5081,  4.3807,  ...,  5.1361,  3.1081,  6.5758]],\n",
       "        device='cuda:0'),\n",
       " tensor(12.8109, device='cuda:0'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['max_aa'], torch.max(ret_dict['max_aa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.6509, -0.3219, -3.6857,  ..., -4.5419, -3.8238, -3.7708],\n",
       "         [-4.3884, -5.1513, -3.2587,  ..., -4.9464, -4.6272, -4.9858],\n",
       "         [-4.3462, -0.4373, -4.0781,  ..., -4.2818, -3.2861, -4.7124],\n",
       "         ...,\n",
       "         [-4.0636, -1.5609, -5.0044,  ..., -5.3047, -3.7902, -2.9418],\n",
       "         [-4.0710, -0.1798, -3.2084,  ..., -3.8164, -3.3576, -5.4531],\n",
       "         [-3.7850, -0.8200, -3.6491,  ..., -4.0723, -3.9764, -2.2733]],\n",
       "        device='cuda:0'),\n",
       " tensor(-10.0609, device='cuda:0'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['min_aa'], torch.min(ret_dict['min_aa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.2488,  1.0751,  3.8374,  ...,  7.8931,  4.2367, 17.8179],\n",
       "         [ 4.4654,  3.3105,  3.2997,  ...,  8.9564,  3.5567, 16.5492],\n",
       "         [ 4.1412,  1.1341,  4.1529,  ...,  7.5512,  4.0450, 21.9785],\n",
       "         ...,\n",
       "         [ 4.8427,  1.4033,  3.2717,  ...,  8.6600,  3.3806, 17.6681],\n",
       "         [ 4.2635,  2.0862,  3.2561,  ...,  6.5544,  3.6153, 19.9038],\n",
       "         [ 4.2699,  1.3731,  3.1090,  ...,  7.6452,  3.7716, 19.3252]],\n",
       "        device='cuda:0'),\n",
       " tensor(58.3277, device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['max_bb'], torch.max(ret_dict['max_bb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0'),\n",
       " tensor(1., device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_dict['min_bb'], torch.min(ret_dict['min_bb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
