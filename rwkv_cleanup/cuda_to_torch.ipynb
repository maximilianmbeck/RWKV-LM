{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/apps/userenv/beck/rwkv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from wkv_kernel import WKV, WKVConfig\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the recurrence formula from CUDA to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /system/user/beck/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /system/user/beck/.cache/torch_extensions/py310_cu117/wkv/build.ninja...\n",
      "Building extension module wkv...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module wkv...\n"
     ]
    }
   ],
   "source": [
    "# Setup cuda kernel\n",
    "wkv_cuda_kernel = WKV()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original input shapes from training\n",
    "batch_size = 12\n",
    "seq_len = 512\n",
    "embedding_dim = 512\n",
    "time_decay = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "time_first = torch.randn(\n",
    "    (embedding_dim, ), dtype=dtype,\n",
    "    device=device).to(memory_format=torch.contiguous_format)\n",
    "k = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "v = torch.randn((batch_size, seq_len, embedding_dim),\n",
    "                device=device,\n",
    "                dtype=dtype).to(memory_format=torch.contiguous_format)\n",
    "y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock up for experiment\n",
    "# batch_size = 2\n",
    "# seq_len = 4\n",
    "# embedding_dim = 2\n",
    "# entries = batch_size * seq_len * embedding_dim\n",
    "# time_decay = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# time_first = torch.arange(embedding_dim, dtype=dtype,\n",
    "#                           device=device).reshape(embedding_dim).to(\n",
    "#                               memory_format=torch.contiguous_format)\n",
    "# k = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# v = torch.arange(entries, dtype=dtype, device=device).reshape(\n",
    "#     batch_size, seq_len,\n",
    "#     embedding_dim).to(memory_format=torch.contiguous_format)\n",
    "# y_gt = torch.empty(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "#                 device=device).to(memory_format=torch.contiguous_format)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkv_cuda_kernel.wkv_cuda.forward(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                             time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5230,  1.4994, -0.4554,  ...,  1.0435,  0.8593,  0.9639],\n",
       "         [ 0.5368, -0.2667,  0.8389,  ...,  0.5313,  0.4112, -0.3319],\n",
       "         [ 0.5379, -0.7265,  1.3164,  ...,  0.3360,  0.2319, -1.1678],\n",
       "         ...,\n",
       "         [ 0.5239, -0.0605, -0.2721,  ...,  0.3394,  0.2285, -0.3610],\n",
       "         [ 0.5239,  0.7317, -0.3268,  ...,  0.3394,  0.2285, -0.3610],\n",
       "         [ 0.5239,  0.6710, -0.0888,  ...,  0.3394,  0.2285, -0.3610]],\n",
       "\n",
       "        [[-0.8473,  1.1180,  0.4535,  ...,  0.5746,  1.9634,  0.7242],\n",
       "         [-0.7122,  0.0837, -0.2143,  ...,  0.2922,  1.6636, -0.2994],\n",
       "         [-0.8010, -0.7374, -0.2310,  ...,  0.2071,  1.6797,  1.5611],\n",
       "         ...,\n",
       "         [-0.8333, -0.4574,  0.6207,  ...,  0.1914,  1.4570,  1.0155],\n",
       "         [-0.8333, -0.3412, -0.4753,  ...,  0.1914,  1.4570,  1.0155],\n",
       "         [-0.8333, -0.2502, -0.5761,  ...,  0.1914,  1.4570,  1.0155]],\n",
       "\n",
       "        [[-0.9110,  0.3784,  0.4915,  ...,  0.3639, -0.5931,  0.5076],\n",
       "         [-0.7329, -0.4737,  0.5772,  ...,  0.5012,  0.4489, -0.0516],\n",
       "         [-0.8561, -0.4716,  0.7191,  ...,  0.5727,  0.1866, -0.0758],\n",
       "         ...,\n",
       "         [-0.8662, -0.4048, -0.1360,  ...,  0.3639,  0.1891,  0.1414],\n",
       "         [-0.8662, -0.5744, -0.0215,  ...,  0.3639,  0.1891,  0.1414],\n",
       "         [-0.8662,  0.5863,  0.6635,  ...,  0.3639,  0.1891,  0.1414]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2193,  0.0456, -0.0790,  ...,  0.6737,  0.8239, -2.2179],\n",
       "         [ 0.2742,  0.1169,  0.1667,  ...,  0.6606,  0.4862, -0.5687],\n",
       "         [ 0.1870,  0.3047,  1.1594,  ...,  0.5829,  0.4919, -1.1951],\n",
       "         ...,\n",
       "         [ 0.2246, -0.8518,  0.4621,  ...,  0.4910,  0.4214, -1.1985],\n",
       "         [ 0.2246, -0.3955,  0.7293,  ...,  0.4910,  0.4214, -1.1985],\n",
       "         [ 0.2246,  0.0496,  0.1110,  ...,  0.4910,  0.4214, -1.1985]],\n",
       "\n",
       "        [[-1.6990, -0.0812, -0.2256,  ..., -1.4248,  0.4200,  1.2747],\n",
       "         [-0.7771, -0.0359, -1.4297,  ..., -1.1081, -1.1014, -1.8761],\n",
       "         [-1.5341,  0.5582, -0.4738,  ..., -0.9707,  0.0641, -0.7411],\n",
       "         ...,\n",
       "         [-1.5487, -0.3181, -0.5450,  ..., -0.9126, -0.1350, -0.9125],\n",
       "         [-1.5487,  1.3821, -0.5100,  ..., -0.9126, -0.1350, -0.9125],\n",
       "         [-1.5487,  1.7170,  0.6459,  ..., -0.9126, -0.1350, -0.9125]],\n",
       "\n",
       "        [[-0.3207, -0.9587,  0.1938,  ...,  0.6931,  0.4183, -0.0031],\n",
       "         [-0.0674, -1.8827,  0.9240,  ...,  1.6261,  0.9102,  0.4364],\n",
       "         [-0.3021, -1.9748,  0.7278,  ...,  0.9649,  0.5464, -0.4336],\n",
       "         ...,\n",
       "         [-0.2973,  0.1358,  1.9782,  ...,  0.6758,  0.4836, -0.1391],\n",
       "         [-0.2973,  0.6430,  0.9393,  ...,  0.6758,  0.4836, -0.1391],\n",
       "         [-0.2973,  0.5328, -0.7196,  ...,  0.6758,  0.4836, -0.1391]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduced torch version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT output:\n",
    "\n",
    "# ww = u_timefirst[c] + k[b, i, c]\n",
    "# p = max(pp, ww)\n",
    "# e1 = exp(pp - p)\n",
    "# e2 = exp(ww - p)\n",
    "# y[b, i, c] = (e1 * aa + e2 * v[b, i, c]) / (e1 * bb + e2)\n",
    "# ww = w_timedecay[c] + pp\n",
    "# p = max(ww, k[b, i, c])\n",
    "# e1 = exp(ww - p)\n",
    "# e2 = exp(k[b, i, c] - p)\n",
    "# aa = e1 * aa + e2 * v[b, i, c]\n",
    "# bb = e1 * bb + e2\n",
    "# pp = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e-38\n",
    "    for b in range(batch_size):\n",
    "        for c in range(embedding_dim):\n",
    "            pp = MIN_VAL\n",
    "            aa = 0\n",
    "            bb = 0\n",
    "            for i in range(seq_len):\n",
    "                # ii = i * embedding_dim + c\n",
    "                kk = k[b, i, c]\n",
    "                vv = v[b, i, c]\n",
    "                ww = time_first[c] + kk\n",
    "                p = torch.tensor(max(pp, ww))\n",
    "                e1 = torch.exp(pp - p)\n",
    "                e2 = torch.exp(ww - p)\n",
    "                new_y = (e1 * aa + e2 * vv) / (e1 * bb + e2)\n",
    "                y[b, i, c] = new_y\n",
    "                ww = time_decay[c] + pp\n",
    "                p = torch.tensor(max(ww, kk))\n",
    "                e1 = torch.exp(ww - p)\n",
    "                e2 = torch.exp(kk - p) # uses current key\n",
    "                aa = e1 * aa + e2 * vv\n",
    "                bb = e1 * bb + e2\n",
    "                pp = p\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_m = cuda_forward_mock(batch_size, seq_len, embedding_dim, time_decay,\n",
    "#                         time_first, k, v, y)\n",
    "# y_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v3 (own impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e-38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    for t in range(seq_len):\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m3 = cuda_forward_mock3(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5230,  1.4994, -0.4554,  ...,  1.0435,  0.8593,  0.9639],\n",
       "         [ 0.5368, -0.2667,  0.8389,  ...,  0.5313,  0.4112, -0.3319],\n",
       "         [ 0.5379, -0.7265,  1.3164,  ...,  0.3360,  0.2319, -1.1678],\n",
       "         ...,\n",
       "         [ 0.5239, -0.0605, -0.2721,  ...,  0.3394,  0.2285, -0.3610],\n",
       "         [ 0.5239,  0.7317, -0.3268,  ...,  0.3394,  0.2285, -0.3610],\n",
       "         [ 0.5239,  0.6710, -0.0888,  ...,  0.3394,  0.2285, -0.3610]],\n",
       "\n",
       "        [[-0.8473,  1.1180,  0.4535,  ...,  0.5746,  1.9634,  0.7242],\n",
       "         [-0.7122,  0.0837, -0.2143,  ...,  0.2922,  1.6636, -0.2994],\n",
       "         [-0.8010, -0.7374, -0.2310,  ...,  0.2071,  1.6797,  1.5611],\n",
       "         ...,\n",
       "         [-0.8333, -0.4574,  0.6207,  ...,  0.1914,  1.4570,  1.0155],\n",
       "         [-0.8333, -0.3412, -0.4753,  ...,  0.1914,  1.4570,  1.0155],\n",
       "         [-0.8333, -0.2502, -0.5761,  ...,  0.1914,  1.4570,  1.0155]],\n",
       "\n",
       "        [[-0.9110,  0.3784,  0.4915,  ...,  0.3639, -0.5931,  0.5076],\n",
       "         [-0.7329, -0.4737,  0.5772,  ...,  0.5012,  0.4489, -0.0516],\n",
       "         [-0.8561, -0.4716,  0.7191,  ...,  0.5727,  0.1866, -0.0758],\n",
       "         ...,\n",
       "         [-0.8662, -0.4048, -0.1360,  ...,  0.3639,  0.1891,  0.1414],\n",
       "         [-0.8662, -0.5744, -0.0215,  ...,  0.3639,  0.1891,  0.1414],\n",
       "         [-0.8662,  0.5863,  0.6635,  ...,  0.3639,  0.1891,  0.1414]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2193,  0.0456, -0.0790,  ...,  0.6737,  0.8239, -2.2179],\n",
       "         [ 0.2742,  0.1169,  0.1667,  ...,  0.6606,  0.4862, -0.5687],\n",
       "         [ 0.1870,  0.3047,  1.1594,  ...,  0.5829,  0.4919, -1.1951],\n",
       "         ...,\n",
       "         [ 0.2246, -0.8518,  0.4621,  ...,  0.4910,  0.4214, -1.1985],\n",
       "         [ 0.2246, -0.3955,  0.7293,  ...,  0.4910,  0.4214, -1.1985],\n",
       "         [ 0.2246,  0.0496,  0.1110,  ...,  0.4910,  0.4214, -1.1985]],\n",
       "\n",
       "        [[-1.6990, -0.0812, -0.2256,  ..., -1.4248,  0.4200,  1.2747],\n",
       "         [-0.7771, -0.0359, -1.4297,  ..., -1.1081, -1.1014, -1.8761],\n",
       "         [-1.5341,  0.5582, -0.4738,  ..., -0.9707,  0.0641, -0.7411],\n",
       "         ...,\n",
       "         [-1.5487, -0.3181, -0.5450,  ..., -0.9126, -0.1350, -0.9125],\n",
       "         [-1.5487,  1.3821, -0.5100,  ..., -0.9126, -0.1350, -0.9125],\n",
       "         [-1.5487,  1.7170,  0.6459,  ..., -0.9126, -0.1350, -0.9125]],\n",
       "\n",
       "        [[-0.3207, -0.9587,  0.1938,  ...,  0.6931,  0.4183, -0.0031],\n",
       "         [-0.0674, -1.8827,  0.9240,  ...,  1.6261,  0.9102,  0.4364],\n",
       "         [-0.3021, -1.9748,  0.7278,  ...,  0.9649,  0.5464, -0.4336],\n",
       "         ...,\n",
       "         [-0.2973,  0.1358,  1.9782,  ...,  0.6758,  0.4836, -0.1391],\n",
       "         [-0.2973,  0.6430,  0.9393,  ...,  0.6758,  0.4836, -0.1391],\n",
       "         [-0.2973,  0.5328, -0.7196,  ...,  0.6758,  0.4836, -0.1391]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m3, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5230,  1.4994],\n",
       "          [ 0.5368, -0.2667]],\n",
       " \n",
       "         [[-0.8473,  1.1180],\n",
       "          [-0.7122,  0.0837]]], device='cuda:0'),\n",
       " tensor([[[ 0.5230,  1.4994],\n",
       "          [ 0.5368, -0.2667]],\n",
       " \n",
       "         [[-0.8473,  1.1180],\n",
       "          [-0.7122,  0.0837]]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gt[:2, :2, :2], y_m3[:2, :2, :2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single computation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "            device=device).to(memory_format=torch.contiguous_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 512, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, seq_len, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape, v.shape, y.shape, time_decay.shape, time_first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ = rearrange(k, 'b s e -> s b e')\n",
    "v_ = rearrange(v, 'b s e -> s b e')\n",
    "y_ = rearrange(y, 'b s e -> s b e')\n",
    "tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "td = repeat(time_decay, 'e -> b e', b=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 12, 512]),\n",
       " torch.Size([512, 12, 512]),\n",
       " torch.Size([12, 512, 512]),\n",
       " torch.Size([12, 512]),\n",
       " torch.Size([12, 512]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_.shape, v_.shape, y.shape, td.shape, tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_VAL = -1e-38\n",
    "aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = tf + k_[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(pp, ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(pp - p)\n",
    "e2 = torch.exp(ww - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = td + pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2691, -2.6967, -1.3070,  ...,  1.1614,  0.4343,  0.4372],\n",
       "        [ 2.2691, -2.6967, -1.3070,  ...,  1.1614,  0.4343,  0.4372],\n",
       "        [ 2.2691, -2.6967, -1.3070,  ...,  1.1614,  0.4343,  0.4372],\n",
       "        ...,\n",
       "        [ 2.2691, -2.6967, -1.3070,  ...,  1.1614,  0.4343,  0.4372],\n",
       "        [ 2.2691, -2.6967, -1.3070,  ...,  1.1614,  0.4343,  0.4372],\n",
       "        [ 2.2691, -2.6967, -1.3070,  ...,  1.1614,  0.4343,  0.4372]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.max(ww, k_[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = torch.exp(ww - p)\n",
    "e2 = torch.exp(k_[t] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = e1 * aa + e2 * v_[t]\n",
    "bb = e1 * bb + e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch version v4 (own impl, simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay,\n",
    "                      time_first, k, v, y):\n",
    "    y = torch.zeros(batch_size, seq_len, embedding_dim, dtype=dtype,\n",
    "                device=device).to(memory_format=torch.contiguous_format)\n",
    "    MIN_VAL = -1e-38\n",
    "    # reshape inputs\n",
    "    k_ = rearrange(k, 'b s e -> s b e')\n",
    "    v_ = rearrange(v, 'b s e -> s b e')\n",
    "    y_ = rearrange(y, 'b s e -> s b e')\n",
    "    tf = repeat(time_first, 'e -> b e', b=batch_size)\n",
    "    td = repeat(time_decay, 'e -> b e', b=batch_size)\n",
    "    # running sums\n",
    "    aa = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    bb = torch.zeros(batch_size, embedding_dim, dtype=dtype, device=device)\n",
    "    pp = torch.full((batch_size, embedding_dim), MIN_VAL, dtype=dtype, device=device)\n",
    "    for t in range(seq_len):\n",
    "        # ww = tf + k_[t]\n",
    "        # p = torch.max(pp, ww)\n",
    "        # e1 = torch.exp(pp - p)\n",
    "        # e2 = torch.exp(ww - p)\n",
    "        # y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        # ww = td + pp\n",
    "        # p = torch.max(ww, k_[t])\n",
    "        # e1 = torch.exp(ww - p)\n",
    "        # e2 = torch.exp(k_[t] - p)\n",
    "        # aa = e1 * aa + e2 * v_[t]\n",
    "        # bb = e1 * bb + e2\n",
    "        # pp = p\n",
    "        ww = tf + k_[t]\n",
    "        p = torch.max(pp, ww)\n",
    "        e1 = torch.exp(pp - p)\n",
    "        e2 = torch.exp(ww - p)\n",
    "        y_[t] = (e1 * aa + e2 * v_[t]) / (e1 * bb + e2)\n",
    "        ww = td + pp\n",
    "        p = torch.max(ww, k_[t])\n",
    "        e1 = torch.exp(ww - p)\n",
    "        e2 = torch.exp(k_[t] - p)\n",
    "        aa = e1 * aa + e2 * v_[t]\n",
    "        bb = e1 * bb + e2\n",
    "        pp = p\n",
    "    y = rearrange(y_, 's b e -> b s e')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m4 = cuda_forward_mock4(batch_size, seq_len, embedding_dim, time_decay, time_first, k, v, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5230,  1.4994, -0.4554,  ...,  1.0435,  0.8593,  0.9639],\n",
       "         [ 0.5368, -0.2667,  0.8389,  ...,  0.5313,  0.4112, -0.3319],\n",
       "         [ 0.5379, -0.7265,  1.3164,  ...,  0.3360,  0.2319, -1.1678],\n",
       "         ...,\n",
       "         [ 0.5239, -0.0605, -0.2721,  ...,  0.3394,  0.2285, -0.3610],\n",
       "         [ 0.5239,  0.7317, -0.3268,  ...,  0.3394,  0.2285, -0.3610],\n",
       "         [ 0.5239,  0.6710, -0.0888,  ...,  0.3394,  0.2285, -0.3610]],\n",
       "\n",
       "        [[-0.8473,  1.1180,  0.4535,  ...,  0.5746,  1.9634,  0.7242],\n",
       "         [-0.7122,  0.0837, -0.2143,  ...,  0.2922,  1.6636, -0.2994],\n",
       "         [-0.8010, -0.7374, -0.2310,  ...,  0.2071,  1.6797,  1.5611],\n",
       "         ...,\n",
       "         [-0.8333, -0.4574,  0.6207,  ...,  0.1914,  1.4570,  1.0155],\n",
       "         [-0.8333, -0.3412, -0.4753,  ...,  0.1914,  1.4570,  1.0155],\n",
       "         [-0.8333, -0.2502, -0.5761,  ...,  0.1914,  1.4570,  1.0155]],\n",
       "\n",
       "        [[-0.9110,  0.3784,  0.4915,  ...,  0.3639, -0.5931,  0.5076],\n",
       "         [-0.7329, -0.4737,  0.5772,  ...,  0.5012,  0.4489, -0.0516],\n",
       "         [-0.8561, -0.4716,  0.7191,  ...,  0.5727,  0.1866, -0.0758],\n",
       "         ...,\n",
       "         [-0.8662, -0.4048, -0.1360,  ...,  0.3639,  0.1891,  0.1414],\n",
       "         [-0.8662, -0.5744, -0.0215,  ...,  0.3639,  0.1891,  0.1414],\n",
       "         [-0.8662,  0.5863,  0.6635,  ...,  0.3639,  0.1891,  0.1414]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2193,  0.0456, -0.0790,  ...,  0.6737,  0.8239, -2.2179],\n",
       "         [ 0.2742,  0.1169,  0.1667,  ...,  0.6606,  0.4862, -0.5687],\n",
       "         [ 0.1870,  0.3047,  1.1594,  ...,  0.5829,  0.4919, -1.1951],\n",
       "         ...,\n",
       "         [ 0.2246, -0.8518,  0.4621,  ...,  0.4910,  0.4214, -1.1985],\n",
       "         [ 0.2246, -0.3955,  0.7293,  ...,  0.4910,  0.4214, -1.1985],\n",
       "         [ 0.2246,  0.0496,  0.1110,  ...,  0.4910,  0.4214, -1.1985]],\n",
       "\n",
       "        [[-1.6990, -0.0812, -0.2256,  ..., -1.4248,  0.4200,  1.2747],\n",
       "         [-0.7771, -0.0359, -1.4297,  ..., -1.1081, -1.1014, -1.8761],\n",
       "         [-1.5341,  0.5582, -0.4738,  ..., -0.9707,  0.0641, -0.7411],\n",
       "         ...,\n",
       "         [-1.5487, -0.3181, -0.5450,  ..., -0.9126, -0.1350, -0.9125],\n",
       "         [-1.5487,  1.3821, -0.5100,  ..., -0.9126, -0.1350, -0.9125],\n",
       "         [-1.5487,  1.7170,  0.6459,  ..., -0.9126, -0.1350, -0.9125]],\n",
       "\n",
       "        [[-0.3207, -0.9587,  0.1938,  ...,  0.6931,  0.4183, -0.0031],\n",
       "         [-0.0674, -1.8827,  0.9240,  ...,  1.6261,  0.9102,  0.4364],\n",
       "         [-0.3021, -1.9748,  0.7278,  ...,  0.9649,  0.5464, -0.4336],\n",
       "         ...,\n",
       "         [-0.2973,  0.1358,  1.9782,  ...,  0.6758,  0.4836, -0.1391],\n",
       "         [-0.2973,  0.6430,  0.9393,  ...,  0.6758,  0.4836, -0.1391],\n",
       "         [-0.2973,  0.5328, -0.7196,  ...,  0.6758,  0.4836, -0.1391]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(y_gt, y_m4, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
